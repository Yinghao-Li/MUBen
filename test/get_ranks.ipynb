{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:40:49.424792Z",
     "start_time": "2023-06-03T20:40:49.421031Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mubench.utils.macro import CLASSIFICATION_DATASET, REGRESSION_DATASET\n",
    "from mubench.utils.io import init_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "CLASSIFICATION_METRICS = ['roc-auc', 'prc-auc', 'ece', 'mce', 'nll', 'brier']\n",
    "REGRESSION_METRICS = ['rmse', 'mae', 'nll', 'ce']\n",
    "LARGER_BETTER_LOOKUP = {\n",
    "    'roc-auc': True,\n",
    "    'prc-auc': True,\n",
    "    'ece': False,\n",
    "    'mce': False,\n",
    "    'nll': False,\n",
    "    'brier': False,\n",
    "    'rmse': False,\n",
    "    'mae': False,\n",
    "    'ce': False\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:39:24.697954Z",
     "start_time": "2023-06-03T20:39:24.694124Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def get_ranks(values, smaller_is_better=True):\n",
    "    arr = np.array(values)\n",
    "    if smaller_is_better:\n",
    "        order = arr.argsort()\n",
    "    else:\n",
    "        order = arr.argsort()[::-1]\n",
    "    rnks = order.argsort()\n",
    "    return rnks + 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:39:25.134773Z",
     "start_time": "2023-06-03T20:39:25.129525Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "result_path = '../output/RESULTS/'\n",
    "score_path = op.join(result_path, 'scores')\n",
    "result_files = list(glob.glob(op.join(score_path, '*.csv')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:39:25.445985Z",
     "start_time": "2023-06-03T20:39:25.440872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "cla_dt_md_unc_mtr = dict()\n",
    "reg_dt_md_unc_mtr = dict()\n",
    "for result_file in result_files:\n",
    "\n",
    "    file_name = op.basename(result_file)\n",
    "    model_name = '-'.join(file_name.split('-')[:-1])\n",
    "    dataset_name = file_name.split('-')[-1].split('.')[0]\n",
    "\n",
    "    if dataset_name in CLASSIFICATION_DATASET:\n",
    "        dataset_model_uncertainty_metric = cla_dt_md_unc_mtr\n",
    "    elif dataset_name in REGRESSION_DATASET:\n",
    "        dataset_model_uncertainty_metric = reg_dt_md_unc_mtr\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    if dataset_name not in dataset_model_uncertainty_metric.keys():\n",
    "        dataset_model_uncertainty_metric[dataset_name] = dict()\n",
    "\n",
    "    df = pd.read_csv(result_file)\n",
    "\n",
    "    uncertainty_methods = df.method\n",
    "    uncertainty_methods = [um.split('-')[-1] for um in uncertainty_methods]\n",
    "\n",
    "    metric_means = [k for k in df.keys() if k.endswith('-mean')]\n",
    "    metric_names = [m[:-5] for m in metric_means]\n",
    "    column_headers = ['method'] + metric_means\n",
    "\n",
    "    uncertainty_metric = dict()\n",
    "    for item in df[column_headers].to_numpy():\n",
    "        uncertainty_method = item[0].split('-')[-1]\n",
    "        metric_values = item[1:]\n",
    "        assert len(metric_values) == len(metric_names)\n",
    "\n",
    "        uncertainty_metric[uncertainty_method] = {n: v for n, v in zip(metric_names, metric_values)}\n",
    "\n",
    "    dataset_model_uncertainty_metric[dataset_name][model_name] = uncertainty_metric\n",
    "\n",
    "cla_fl_dt_md_unc_mtr = pd.json_normalize(cla_dt_md_unc_mtr, sep='_').to_dict()\n",
    "reg_fl_dt_md_unc_mtr = pd.json_normalize(reg_dt_md_unc_mtr, sep='_').to_dict()\n",
    "\n",
    "cla_dt_fl_md_unc_mtr = {dt: pd.json_normalize(cla_md_unc_mtr, sep='_').to_dict() for dt, cla_md_unc_mtr in cla_dt_md_unc_mtr.items()}\n",
    "reg_dt_fl_md_unc_mtr = {dt: pd.json_normalize(reg_md_unc_mtr, sep='_').to_dict() for dt, reg_md_unc_mtr in reg_dt_md_unc_mtr.items()}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:39:25.852005Z",
     "start_time": "2023-06-03T20:39:25.697822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "classification_datasets = list(cla_dt_fl_md_unc_mtr.keys())\n",
    "regression_datasets = list(reg_dt_fl_md_unc_mtr.keys())\n",
    "\n",
    "cla_metric_ranks = {dt: {mtr: dict() for mtr in CLASSIFICATION_METRICS} for dt in classification_datasets}\n",
    "reg_metric_ranks = {dt: {mtr: dict() for mtr in REGRESSION_METRICS} for dt in regression_datasets}\n",
    "\n",
    "for dt, mtr_vals in cla_metric_ranks.items():\n",
    "    for mtr in mtr_vals:\n",
    "        md_unc_scores = {'_'.join(k.split('_')[1:-1]): val[0] for k, val in cla_fl_dt_md_unc_mtr.items() if k.startswith(dt) and k.endswith(mtr)}\n",
    "        ranks = get_ranks(list(md_unc_scores.values()), smaller_is_better=not LARGER_BETTER_LOOKUP[mtr])\n",
    "        md_unc_ranks = {k: r for k, r in zip(md_unc_scores, ranks)}\n",
    "        mtr_vals[mtr] = md_unc_ranks\n",
    "\n",
    "for dt, mtr_vals in reg_metric_ranks.items():\n",
    "    for mtr in mtr_vals:\n",
    "        md_unc_scores = {'_'.join(k.split('_')[1:-1]): val[0] for k, val in reg_fl_dt_md_unc_mtr.items() if k.startswith(dt) and k.endswith(mtr)}\n",
    "        ranks = get_ranks(list(md_unc_scores.values()), smaller_is_better=not LARGER_BETTER_LOOKUP[mtr])\n",
    "        md_unc_ranks = {k: r for k, r in zip(md_unc_scores, ranks)}\n",
    "        mtr_vals[mtr] = md_unc_ranks\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:39:26.324035Z",
     "start_time": "2023-06-03T20:39:26.322796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "output_dir = op.join(result_path, 'ranks')\n",
    "init_dir(output_dir)\n",
    "\n",
    "for dataset in classification_datasets:\n",
    "    dataset_metric_ranks = cla_metric_ranks[dataset]\n",
    "    df = pd.DataFrame(dataset_metric_ranks)\n",
    "    df.to_csv(op.join(output_dir, f'{dataset}.csv'))\n",
    "\n",
    "for dataset in regression_datasets:\n",
    "    dataset_metric_ranks = reg_metric_ranks[dataset]\n",
    "    df = pd.DataFrame(dataset_metric_ranks)\n",
    "    df.to_csv(op.join(output_dir, f'{dataset}.csv'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:40:53.030745Z",
     "start_time": "2023-06-03T20:40:53.013174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
