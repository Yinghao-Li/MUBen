{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:36:09.354946Z",
     "start_time": "2023-06-13T17:36:09.081264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mubench.utils.macro import CLASSIFICATION_DATASET, REGRESSION_DATASET\n",
    "from mubench.utils.io import init_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:42:25.145605Z",
     "start_time": "2023-06-13T17:42:25.139251Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLASSIFICATION_METRICS = ['roc-auc', 'ece', 'nll', 'brier']\n",
    "REGRESSION_METRICS = ['rmse', 'mae', 'nll', 'ce']\n",
    "metrics_mapping = {\n",
    "    'roc-auc': 'ROC-AUC',\n",
    "    'ece': 'ECE',\n",
    "    'nll': 'NLL',\n",
    "    'brier': 'BS',\n",
    "    'rmse': 'RMSE',\n",
    "    'mae': 'MAE',\n",
    "    'ce': 'CE'\n",
    "}\n",
    "MODEL_NAMES = [\n",
    "    \"DNN-rdkit\",\n",
    "    \"ChemBERTa\",\n",
    "    \"GROVER\",\n",
    "    \"Uni-Mol\"\n",
    "]\n",
    "model_mapping = {\n",
    "    \"DNN-rdkit\": 'DNN',\n",
    "    \"ChemBERTa\": \"ChemBERTa\",\n",
    "    \"GROVER\": \"GROVER\",\n",
    "    \"Uni-Mol\": \"Uni-Mol\"\n",
    "}\n",
    "CLASSIFICATION_UNCERTAINTY = [\n",
    "    'none',\n",
    "    'TemperatureScaling',\n",
    "    'FocalLoss',\n",
    "    'MCDropout',\n",
    "    'SWAG',\n",
    "    'BBP',\n",
    "    'SGLD',\n",
    "    'DeepEnsembles'\n",
    "]\n",
    "REGRESSION_UNCERTAINTY = [\n",
    "    'none',\n",
    "    'MCDropout',\n",
    "    'SWAG',\n",
    "    'BBP',\n",
    "    'SGLD',\n",
    "    'DeepEnsembles'\n",
    "]\n",
    "uncertainty_mapping = {\n",
    "    'none': 'Deterministic',\n",
    "    'TemperatureScaling': 'Temperature',\n",
    "    'FocalLoss': 'Focal Loss',\n",
    "    'MCDropout': 'MC Dropout',\n",
    "    'SWAG': 'SWAG',\n",
    "    'BBP': 'BBP',\n",
    "    'SGLD': 'SGLD',\n",
    "    'DeepEnsembles': 'Ensembles'\n",
    "}\n",
    "dataset_mapping = {\n",
    "    \"tox21\": \"Tox21\",\n",
    "    \"esol\": \"ESOL\",\n",
    "    \"freesolv\": \"FreeSolv\",\n",
    "    \"lipo\": \"Lipophilicity\",\n",
    "    \"muv\": \"MUV\",\n",
    "    \"hiv\": \"HIV\",\n",
    "    \"bace\": \"BACE\",\n",
    "    \"bbbp\": \"BBBP\",\n",
    "    \"toxcast\": \"ToxCast\",\n",
    "    \"sider\": \"SIDER\",\n",
    "    \"clintox\": \"ClinTox\",\n",
    "    \"qm7\": \"QM7\",\n",
    "    \"qm8\": \"QM8\",\n",
    "    \"qm9\": \"QM9\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:36:15.828691Z",
     "start_time": "2023-06-13T17:36:15.824212Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_path = '../output/RESULTS/'\n",
    "score_path = op.join(result_path, 'scores')\n",
    "result_files = list(glob.glob(op.join(score_path, '*.csv')))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## For classification datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T18:01:28.257613Z",
     "start_time": "2023-06-13T18:01:28.158317Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapped_metrics = [metrics_mapping[m] for m in CLASSIFICATION_METRICS]\n",
    "for dataset in CLASSIFICATION_DATASET:\n",
    "    dfs = list()\n",
    "    for model_name in MODEL_NAMES:\n",
    "        result_file = op.join(score_path, f\"{model_name}-{dataset}.csv\")\n",
    "        df = pd.read_csv(result_file, index_col='method')\n",
    "        for metrics in CLASSIFICATION_METRICS:\n",
    "            df[metrics_mapping[metrics]] = [(f\"{m:.4f}\" if m == m else '(-)') + \" \" + (f\"({s:.4f})\" if s == s else '(-)')\n",
    "                                            for m, s in zip(df[f'{metrics}-mean'], df[f'{metrics}-std'])]\n",
    "        df = df[mapped_metrics]\n",
    "        df = df.reindex([f'{model_name}-{unc}' for unc in CLASSIFICATION_UNCERTAINTY])\n",
    "        index_mapping = {f\"{model_name}-{unc}\": uncertainty_mapping[unc] for unc in CLASSIFICATION_UNCERTAINTY}\n",
    "        df = df.rename(index=index_mapping)\n",
    "        index = pd.MultiIndex.from_tuples([(model_name, unc) for unc in df.index])\n",
    "        df = df.set_index(index)\n",
    "        dfs.append(df)\n",
    "\n",
    "    data_df = pd.concat(dfs)\n",
    "    data_df.to_latex(f\"tb3.result.dataset.{dataset}.tex\",\n",
    "                     caption=f\"Test results on {dataset_mapping[dataset]} in the format of ``metric mean (standard deviation)''.\",\n",
    "                     label=f\"apptb:result.dataset.{dataset}\",\n",
    "                     position='tbh')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T18:23:03.776012Z",
     "start_time": "2023-06-13T18:23:03.700979Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapped_metrics = [metrics_mapping[m] for m in REGRESSION_METRICS]\n",
    "for dataset in REGRESSION_DATASET:\n",
    "    dfs = list()\n",
    "    for model_name in MODEL_NAMES:\n",
    "        result_file = op.join(score_path, f\"{model_name}-{dataset}.csv\")\n",
    "        df = pd.read_csv(result_file, index_col='method')\n",
    "        for metrics in REGRESSION_METRICS:\n",
    "            df[metrics_mapping[metrics]] = [(f\"{m:.4f}\" if m == m else '(-)') + \" \" + (f\"({s:.4f})\" if s == s else '(-)')\n",
    "                                            for m, s in zip(df[f'{metrics}-mean'], df[f'{metrics}-std'])]\n",
    "        df = df[mapped_metrics]\n",
    "        df = df.reindex([f'{model_name}-{unc}' for unc in REGRESSION_UNCERTAINTY])\n",
    "        index_mapping = {f\"{model_name}-{unc}\": uncertainty_mapping[unc] for unc in REGRESSION_UNCERTAINTY}\n",
    "        df = df.rename(index=index_mapping)\n",
    "        index = pd.MultiIndex.from_tuples([(model_name, unc) for unc in df.index])\n",
    "        df = df.set_index(index)\n",
    "        dfs.append(df)\n",
    "\n",
    "    data_df = pd.concat(dfs)\n",
    "    data_df.to_latex(f\"tb3.result.dataset.{dataset}.tex\",\n",
    "                     caption=f\"Test results on {dataset_mapping[dataset]} in the format of ``metric mean (standard deviation)''.\",\n",
    "                     label=f\"apptb:result.dataset.{dataset}\",\n",
    "                     position='tbh')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
