{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MUBen Documentation Info This is the documentation for MUBen : Mulecular Uncertainty Benchmark . The code is built to expose implementation details as much as possible and be easily extendable. Questions and suggestions are welcome if you find any issues while using our code. MUBen is a benchmark that aims to investigate the performance of uncertainty quantification (UQ) methods built upon backbone molecular representation models. It implements 6 backbone models (4 pre-trained and 2 non-pre-trained), 8 UQ methods (8 compatible for classification and 6 for regression), and 14 datasets from MoleculeNet (8 for classification and 6 for regression). We are actively expanding the benchmark to include more backbones, UQ methods and datasets. This is an arduous task, and we welcome contribution or collaboration in any form. Info The following of this page introduces the basic information and structure of the MUBen project. For its utilization or customization, please visit the Experiments or Customization pages. Backbones The following backbone models are implemented in MUBen, and their performance discussed in the published article. Backbone Models Paper Official Repo Pre-Trained ChemBERTa link link GROVER link link Uni-Mol link link TorchMD-NET Architecture ; Pre-training link Trained from Scratch DNN - - GIN link pyg MUBen also support easy integration of your own backbone models. To use your own backbones, please check the customization guide . Uncertainty Quantification Methods Currently, MUBen supports the following uncertainty quantification methods. Notice that some methods only work with one of the classification/regression task. UQ Method Classification Regression Paper Included in Paper Deterministic \u2705\ufe0e \u2705\ufe0e - Temperature Scaling \u2705\ufe0e - link Focal Loss \u2705\ufe0e - link Deep Ensembles \u2705\ufe0e \u2705\ufe0e link SWAG \u2705\ufe0e \u2705\ufe0e link Bayes by Backprop \u2705\ufe0e \u2705\ufe0e link SGLD \u2705\ufe0e \u2705\ufe0e link MC Dropout \u2705\ufe0e \u2705\ufe0e link Additional in Repo Evidential Networks \u2705\ufe0e \u2705\ufe0e link Conformal Prediction - \u2705\ufe0e link Isotonic Calibration - \u2705\ufe0e link Data Info The prepared scaffold-split data is available in the ./data/files/ directory on GitHub. This documentation utilizes a selection from the MoleculeNet benchmark, which includes datasets such as BBBP, Tox21, ToxCast, SIDER, ClinTox, BACE, MUV, HIV, ESOL, FreeSolv, Lipophilicity, QM7, QM8, and QM9. For detailed descriptions of these datasets, please refer to the MoleculeNet website . We employ the \"molecular property\" datasets curated by Uni-Mol , which are accessible for download here . While the original Uni-Mol dataset is generally not necessary, it is used to provide pre-defined molecule conformations for running the Uni-Mol model. To use the Uni-Mol data, download and unzip the files into the ./data/UniMol/ directory. For ease of reference, you are suggested to rename the qm7dft , qm8dft , and qm9dft directories to qm7 , qm8 , and qm9 , respectively. The conversion of the dataset format from Uni-Mol to our specifications can be viewed in the script dataset_build_from_unimol.py . Typically, each dataset comprises 4 files: train.csv , valid.csv , test.csv , and meta.json . The .csv files partition the data into training, validation, and testing sets, while meta.json contains metadata such as task type (classification or regression), number of tasks, and number of classes (for classification tasks). Each .csv file contains three columns: - smiles : A string representing the SMILES notation of a molecule. - labels : A list of integers or floats representing the property values to be predicted for each molecule. The length of the list corresponds to the number of tasks. - masks : A binary list (containing 0s and 1s) where 1 indicates a valid property value and 0 indicates an invalid value to be ignored during training and testing. The dataset is automatically loaded during training through the method muben.dataset.Dataset.prepare() . For a practical example, visit the example page. Experimental Results We have made our experimental results available in the ./reports/ directory on GitHub. These results are organized into different folders based on the nature of the experiments: primary : Contains the most comprehensive set of results derived from experiments on scaffold-split datasets. random : Includes results from experiments conducted on datasets that were split randomly. frozen : Features results from experiments where the pre-trained model's weights were frozen, except for the last output layer, which was updatable. distribution : Offers results from the QM9 dataset, where the test set was categorized into five bins based on the average Tanimoto similarities to the training scaffolds. Files within these directories are named following the pattern <backbone>-<dataset>.csv . Each file provides a comparison of different UQ methods. The rows detail the performance of each UQ method, while the columns display the mean and standard deviation from three random runs for each metric. Additional post-processing scripts can be found in the ./assist/ directory, which include files starting with plot_ or results_ . These scripts are useful for further analysis and visualization of the experimental data. Ongoing Works: Active Learning We are developing code to integrate active learning into the pipeline. Specifically, we assume we have a small set of labeled data points ( --n_init_instances ) at the beginning. Within each active learning iteration, we use the labeled dataset to fine-tune the model parameters and select a batch of data points ( --n_al_select ) from the unlabeled set with the least predicted certainty ( i.e. , max predicted entropy for classification and max predicted variance for regression). The process is repeated for several loops ( --n_al_loops ), and the intermediate performance is tracked. The code is still under construction and currently is only available under the dev branch . In addition, several points are worth attention: Currently, only DNN and ChemBERTa backbones are supported ( ./run/dnn_al.py and ./run/chemberta_al.py ). Migrating AL to other backbones is not difficult but requires updating some Trainer functions if they are reloaded. To enable active learning, make sure you set --enable_active_learning to true . Currently, Deep Ensembles is not supported for AL. We cannot guarantee the correctness of our implementation. If you notice any abnormalities in the code, please do not hesitate to post an issue. One example is python ./run/dnn_al.py \\ --enable_active_learning \\ --n_init_instances 100 \\ --n_al_loops 20 \\ --n_al_select 20 \\ # other model and training hyper-parameters... Citation If you find our work helpful, please consider citing it as @misc{li2023muben, title={MUBen: Benchmarking the Uncertainty of Pre-Trained Models for Molecular Property Prediction}, author={Yinghao Li and Lingkai Kong and Yuanqi Du and Yue Yu and Yuchen Zhuang and Wenhao Mu and Chao Zhang}, year={2023}, eprint={2306.10060}, archivePrefix={arXiv}, primaryClass={physics.chem-ph} }","title":"About"},{"location":"#muben-documentation","text":"Info This is the documentation for MUBen : Mulecular Uncertainty Benchmark . The code is built to expose implementation details as much as possible and be easily extendable. Questions and suggestions are welcome if you find any issues while using our code. MUBen is a benchmark that aims to investigate the performance of uncertainty quantification (UQ) methods built upon backbone molecular representation models. It implements 6 backbone models (4 pre-trained and 2 non-pre-trained), 8 UQ methods (8 compatible for classification and 6 for regression), and 14 datasets from MoleculeNet (8 for classification and 6 for regression). We are actively expanding the benchmark to include more backbones, UQ methods and datasets. This is an arduous task, and we welcome contribution or collaboration in any form. Info The following of this page introduces the basic information and structure of the MUBen project. For its utilization or customization, please visit the Experiments or Customization pages.","title":"MUBen Documentation"},{"location":"#backbones","text":"The following backbone models are implemented in MUBen, and their performance discussed in the published article. Backbone Models Paper Official Repo Pre-Trained ChemBERTa link link GROVER link link Uni-Mol link link TorchMD-NET Architecture ; Pre-training link Trained from Scratch DNN - - GIN link pyg MUBen also support easy integration of your own backbone models. To use your own backbones, please check the customization guide .","title":"Backbones"},{"location":"#uncertainty-quantification-methods","text":"Currently, MUBen supports the following uncertainty quantification methods. Notice that some methods only work with one of the classification/regression task. UQ Method Classification Regression Paper Included in Paper Deterministic \u2705\ufe0e \u2705\ufe0e - Temperature Scaling \u2705\ufe0e - link Focal Loss \u2705\ufe0e - link Deep Ensembles \u2705\ufe0e \u2705\ufe0e link SWAG \u2705\ufe0e \u2705\ufe0e link Bayes by Backprop \u2705\ufe0e \u2705\ufe0e link SGLD \u2705\ufe0e \u2705\ufe0e link MC Dropout \u2705\ufe0e \u2705\ufe0e link Additional in Repo Evidential Networks \u2705\ufe0e \u2705\ufe0e link Conformal Prediction - \u2705\ufe0e link Isotonic Calibration - \u2705\ufe0e link","title":"Uncertainty Quantification Methods"},{"location":"#data","text":"Info The prepared scaffold-split data is available in the ./data/files/ directory on GitHub. This documentation utilizes a selection from the MoleculeNet benchmark, which includes datasets such as BBBP, Tox21, ToxCast, SIDER, ClinTox, BACE, MUV, HIV, ESOL, FreeSolv, Lipophilicity, QM7, QM8, and QM9. For detailed descriptions of these datasets, please refer to the MoleculeNet website . We employ the \"molecular property\" datasets curated by Uni-Mol , which are accessible for download here . While the original Uni-Mol dataset is generally not necessary, it is used to provide pre-defined molecule conformations for running the Uni-Mol model. To use the Uni-Mol data, download and unzip the files into the ./data/UniMol/ directory. For ease of reference, you are suggested to rename the qm7dft , qm8dft , and qm9dft directories to qm7 , qm8 , and qm9 , respectively. The conversion of the dataset format from Uni-Mol to our specifications can be viewed in the script dataset_build_from_unimol.py . Typically, each dataset comprises 4 files: train.csv , valid.csv , test.csv , and meta.json . The .csv files partition the data into training, validation, and testing sets, while meta.json contains metadata such as task type (classification or regression), number of tasks, and number of classes (for classification tasks). Each .csv file contains three columns: - smiles : A string representing the SMILES notation of a molecule. - labels : A list of integers or floats representing the property values to be predicted for each molecule. The length of the list corresponds to the number of tasks. - masks : A binary list (containing 0s and 1s) where 1 indicates a valid property value and 0 indicates an invalid value to be ignored during training and testing. The dataset is automatically loaded during training through the method muben.dataset.Dataset.prepare() . For a practical example, visit the example page.","title":"Data"},{"location":"#experimental-results","text":"We have made our experimental results available in the ./reports/ directory on GitHub. These results are organized into different folders based on the nature of the experiments: primary : Contains the most comprehensive set of results derived from experiments on scaffold-split datasets. random : Includes results from experiments conducted on datasets that were split randomly. frozen : Features results from experiments where the pre-trained model's weights were frozen, except for the last output layer, which was updatable. distribution : Offers results from the QM9 dataset, where the test set was categorized into five bins based on the average Tanimoto similarities to the training scaffolds. Files within these directories are named following the pattern <backbone>-<dataset>.csv . Each file provides a comparison of different UQ methods. The rows detail the performance of each UQ method, while the columns display the mean and standard deviation from three random runs for each metric. Additional post-processing scripts can be found in the ./assist/ directory, which include files starting with plot_ or results_ . These scripts are useful for further analysis and visualization of the experimental data.","title":"Experimental Results"},{"location":"#ongoing-works-active-learning","text":"We are developing code to integrate active learning into the pipeline. Specifically, we assume we have a small set of labeled data points ( --n_init_instances ) at the beginning. Within each active learning iteration, we use the labeled dataset to fine-tune the model parameters and select a batch of data points ( --n_al_select ) from the unlabeled set with the least predicted certainty ( i.e. , max predicted entropy for classification and max predicted variance for regression). The process is repeated for several loops ( --n_al_loops ), and the intermediate performance is tracked. The code is still under construction and currently is only available under the dev branch . In addition, several points are worth attention: Currently, only DNN and ChemBERTa backbones are supported ( ./run/dnn_al.py and ./run/chemberta_al.py ). Migrating AL to other backbones is not difficult but requires updating some Trainer functions if they are reloaded. To enable active learning, make sure you set --enable_active_learning to true . Currently, Deep Ensembles is not supported for AL. We cannot guarantee the correctness of our implementation. If you notice any abnormalities in the code, please do not hesitate to post an issue. One example is python ./run/dnn_al.py \\ --enable_active_learning \\ --n_init_instances 100 \\ --n_al_loops 20 \\ --n_al_select 20 \\ # other model and training hyper-parameters...","title":"Ongoing Works: Active Learning"},{"location":"#citation","text":"If you find our work helpful, please consider citing it as @misc{li2023muben, title={MUBen: Benchmarking the Uncertainty of Pre-Trained Models for Molecular Property Prediction}, author={Yinghao Li and Lingkai Kong and Yuanqi Du and Yue Yu and Yuchen Zhuang and Wenhao Mu and Chao Zhang}, year={2023}, eprint={2306.10060}, archivePrefix={arXiv}, primaryClass={physics.chem-ph} }","title":"Citation"},{"location":"customize/","text":"Customization We have shown in the previous sections how to reproduce our results through a Python (Jupyter) script or command line interface. In this section, we focus on extending our benchmark to more datasets and backbone models. Note We have also tried to modulate the UQ methods. However, it seems that most of their implementations are deeply entangled with the model architecture and training process. Therefore, we only provide a limited selection of UQ methods in MUBen and leave its extension to the community. Customize dataset Prepare the dataset Training the backbone/UQ methods with a customized dataset is quite straightforward. If you want to test the UQ methods on your own dataset, you can organize your data as pandas.DataFrame with three keys: [\"smiles\", \"labels\", \"masks\"] . Their types are shown below. { \"smiles\": list of `str`, \"labels\": list of list of int/float, \"masks\": list of list of int/float (with values within {0,1}) } Here, mask=1 indicates the existence informative label at the position and mask=0 indicates the missing label. Note You should store your molecules using smiles even if you choose other descriptors such as 2D and 3D graphs. The graphs or RDKit features could be constructed during data pre-processing within the training process. The training, validation, and test partitions should be stored as train.csv , valid.csv , and test.csv files respectively in the same folder. The .csv files should be accompanied by a meta.json file within the same directory. It stores some constant dataset properties, e.g. , task_type (classification or regression), n_tasks , or classes ( [0,1] for all our classification datasets). For the customized dataset, one required property is the eval_metric for validation and testing ( e.g. , roc-auc, rmse, etc. ). You can check the prepared datasets included in our program for reference. You are recommended to put the dataset files in the ./data/file/<dataset name> directory, but you can of course choose your favorite location and specify the --data_folder argument. Train the model To conduct training and evaluation on the customized dataset, we only need to modify the dataset_name argument ( muben.args ) to the name of the customized dataset. This can be achieved through both CLI ( --dataset_name <the name of your dataset> ) or within the Python script ( config.dataset_name=\"<the name of your dataset>\" ). Note Notice that dataset_name only contains the name of the specific dataset folder instead of the entire path to a specific file. The full path to the training partition, for example, is constructed from <dataset_folder>/<dataset_name>/train.csv . Customize backbone model It is also easy to define a customized backbone model and integrate it into the training & evaluation pipeline, as long as it follows the standard input & output format. In the following example, we manually construct a DNN model that uses RDKit features as input. Define the model The following code defines a conventional DNN model with customizable input/output/hidden dimensionalities and dropout probabilities. For the output layer, we use the OutputLayer class defined in muben.layers module to realize easy initialization and integration of Bayes-by-Backprop (BBP). import torch.nn as nn from muben.layers import OutputLayer class DNN(nn.Module): def __init__(self, d_feature: int, n_lbs: int, n_tasks: int, hidden_dims: list[int], p_dropout: float = 0.1, uncertainty_method: str = \"none\", **kwargs): super().__init__() # d_feature = config.d_feature # n_lbs = config.n_lbs # n_tasks = config.n_tasks # n_hidden_layers = config.n_dnn_hidden_layers # d_hidden = config.d_dnn_hidden # p_dropout = config.dropout # uncertainty_method = config.uncertainty_method if hidden_dims is None: hidden_dims = [d_hidden] * (n_hidden_layers + 1) else: n_hidden_layers = len(hidden_dims) self.input_layer = nn.Sequential( nn.Linear(d_feature, hidden_dims[0]), nn.ReLU(), nn.Dropout(p_dropout), ) hidden_layers = [ nn.Sequential( nn.Linear(hidden_dims[i], hidden_dims[i + 1]), nn.ReLU(), nn.Dropout(p_dropout), ) for i in range(n_hidden_layers) ] self.hidden_layers = nn.Sequential(*hidden_layers) self.output_layer = OutputLayer( hidden_dims[-1], n_lbs * n_tasks, uncertainty_method, **kwargs ) self.initialize() def initialize(self): def init_weights(m): if isinstance(m, nn.Linear): nn.init.xavier_uniform_(m.weight) m.bias.data.fill_(0.01) self.apply(init_weights) self.output_layer.initialize() return self def forward(self, batch): features = batch.features x = self.input_layer(features) x = self.hidden_layers(x) logits = self.output_layer(x) return logits Initialize trainer with customized model Once the model is defined, we can pass it as an argument to the Trainer class to set it as the backbone mode. Notice that when the model is referred to but not initialized together with Trainer . For example, we can use the same code in the simple example for Trainer initialization. from muben.args import Config from muben.utils.selectors import dataset_selector, model_selector from muben.train import Trainer descriptor_type = \"RDKit\" # as mentioned above, we use RDKit features here config_class = configure_selector(descriptor_type) dataset_class = dataset_selector(descriptor_type) config = Config() # We'll can the default configuration for customized backbone models # io configurations config.feature_type = \"rdkit\" config.data_folder = \"./data/files/\" config.dataset_name = \"bbbp\" config.result_folder = \"./output-demo/\" config.uncertainty_method = \"none\" # here \"none\" refers to \"Deterministic\" # training configurations config.retrain_model = True config.n_epochs = 50 config.lr = 0.0001 # we'll leave model configurations config.__post_init__() config.get_meta().validate() # Load and process the training, validation and test datasets dataset_class, collator_class = dataset_selector(descriptor_type) training_dataset = dataset_class().prepare(config=config, partition=\"train\") valid_dataset = dataset_class().prepare(config=config, partition=\"valid\") test_dataset = dataset_class().prepare(config=config, partition=\"test\") # Inintialized the trainer with the configuration and datasets trainer = Trainer( config=config, model_class=DNN, # passed the customized model class to the Trainer training_dataset=training_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset, collate_fn=collator_class(config), ) With the above code, we have initialized the trainer with DNN as well as RDKit datasets. However, the model is not initialized. To initialize the model, we can use trainer.initialize . trainer.initialize( d_feature = 200 # the feature dimensionality has to be the same as the output of your feature generator n_lbs = 1 # bbbp dataset has 2 label types (0, 1), but we use only 1 classification head for binary classification n_tasks = 1 # bbbp dataset has 1 tasks hidden_dims = [512, 512, 512] # 3 hidden layer, each with dimensionality 512 uncertainty_method = \"MCDropout\" # set the uncertainty method as MC Dropout ) The keyword arguments passed to trainer.initialize should be the same as what you have defined in DNN.__init__ as we use **kwargs to pass these arguments. If the keywords are different, the model may not be initialized properly. Once the trainer has been initialized, we can start the training and evaluation process as we demonstrated before. trainer.run()","title":"Customization"},{"location":"customize/#customization","text":"We have shown in the previous sections how to reproduce our results through a Python (Jupyter) script or command line interface. In this section, we focus on extending our benchmark to more datasets and backbone models. Note We have also tried to modulate the UQ methods. However, it seems that most of their implementations are deeply entangled with the model architecture and training process. Therefore, we only provide a limited selection of UQ methods in MUBen and leave its extension to the community.","title":"Customization"},{"location":"customize/#customize-dataset","text":"","title":"Customize dataset"},{"location":"customize/#prepare-the-dataset","text":"Training the backbone/UQ methods with a customized dataset is quite straightforward. If you want to test the UQ methods on your own dataset, you can organize your data as pandas.DataFrame with three keys: [\"smiles\", \"labels\", \"masks\"] . Their types are shown below. { \"smiles\": list of `str`, \"labels\": list of list of int/float, \"masks\": list of list of int/float (with values within {0,1}) } Here, mask=1 indicates the existence informative label at the position and mask=0 indicates the missing label. Note You should store your molecules using smiles even if you choose other descriptors such as 2D and 3D graphs. The graphs or RDKit features could be constructed during data pre-processing within the training process. The training, validation, and test partitions should be stored as train.csv , valid.csv , and test.csv files respectively in the same folder. The .csv files should be accompanied by a meta.json file within the same directory. It stores some constant dataset properties, e.g. , task_type (classification or regression), n_tasks , or classes ( [0,1] for all our classification datasets). For the customized dataset, one required property is the eval_metric for validation and testing ( e.g. , roc-auc, rmse, etc. ). You can check the prepared datasets included in our program for reference. You are recommended to put the dataset files in the ./data/file/<dataset name> directory, but you can of course choose your favorite location and specify the --data_folder argument.","title":"Prepare the dataset"},{"location":"customize/#train-the-model","text":"To conduct training and evaluation on the customized dataset, we only need to modify the dataset_name argument ( muben.args ) to the name of the customized dataset. This can be achieved through both CLI ( --dataset_name <the name of your dataset> ) or within the Python script ( config.dataset_name=\"<the name of your dataset>\" ). Note Notice that dataset_name only contains the name of the specific dataset folder instead of the entire path to a specific file. The full path to the training partition, for example, is constructed from <dataset_folder>/<dataset_name>/train.csv .","title":"Train the model"},{"location":"customize/#customize-backbone-model","text":"It is also easy to define a customized backbone model and integrate it into the training & evaluation pipeline, as long as it follows the standard input & output format. In the following example, we manually construct a DNN model that uses RDKit features as input.","title":"Customize backbone model"},{"location":"customize/#define-the-model","text":"The following code defines a conventional DNN model with customizable input/output/hidden dimensionalities and dropout probabilities. For the output layer, we use the OutputLayer class defined in muben.layers module to realize easy initialization and integration of Bayes-by-Backprop (BBP). import torch.nn as nn from muben.layers import OutputLayer class DNN(nn.Module): def __init__(self, d_feature: int, n_lbs: int, n_tasks: int, hidden_dims: list[int], p_dropout: float = 0.1, uncertainty_method: str = \"none\", **kwargs): super().__init__() # d_feature = config.d_feature # n_lbs = config.n_lbs # n_tasks = config.n_tasks # n_hidden_layers = config.n_dnn_hidden_layers # d_hidden = config.d_dnn_hidden # p_dropout = config.dropout # uncertainty_method = config.uncertainty_method if hidden_dims is None: hidden_dims = [d_hidden] * (n_hidden_layers + 1) else: n_hidden_layers = len(hidden_dims) self.input_layer = nn.Sequential( nn.Linear(d_feature, hidden_dims[0]), nn.ReLU(), nn.Dropout(p_dropout), ) hidden_layers = [ nn.Sequential( nn.Linear(hidden_dims[i], hidden_dims[i + 1]), nn.ReLU(), nn.Dropout(p_dropout), ) for i in range(n_hidden_layers) ] self.hidden_layers = nn.Sequential(*hidden_layers) self.output_layer = OutputLayer( hidden_dims[-1], n_lbs * n_tasks, uncertainty_method, **kwargs ) self.initialize() def initialize(self): def init_weights(m): if isinstance(m, nn.Linear): nn.init.xavier_uniform_(m.weight) m.bias.data.fill_(0.01) self.apply(init_weights) self.output_layer.initialize() return self def forward(self, batch): features = batch.features x = self.input_layer(features) x = self.hidden_layers(x) logits = self.output_layer(x) return logits","title":"Define the model"},{"location":"customize/#initialize-trainer-with-customized-model","text":"Once the model is defined, we can pass it as an argument to the Trainer class to set it as the backbone mode. Notice that when the model is referred to but not initialized together with Trainer . For example, we can use the same code in the simple example for Trainer initialization. from muben.args import Config from muben.utils.selectors import dataset_selector, model_selector from muben.train import Trainer descriptor_type = \"RDKit\" # as mentioned above, we use RDKit features here config_class = configure_selector(descriptor_type) dataset_class = dataset_selector(descriptor_type) config = Config() # We'll can the default configuration for customized backbone models # io configurations config.feature_type = \"rdkit\" config.data_folder = \"./data/files/\" config.dataset_name = \"bbbp\" config.result_folder = \"./output-demo/\" config.uncertainty_method = \"none\" # here \"none\" refers to \"Deterministic\" # training configurations config.retrain_model = True config.n_epochs = 50 config.lr = 0.0001 # we'll leave model configurations config.__post_init__() config.get_meta().validate() # Load and process the training, validation and test datasets dataset_class, collator_class = dataset_selector(descriptor_type) training_dataset = dataset_class().prepare(config=config, partition=\"train\") valid_dataset = dataset_class().prepare(config=config, partition=\"valid\") test_dataset = dataset_class().prepare(config=config, partition=\"test\") # Inintialized the trainer with the configuration and datasets trainer = Trainer( config=config, model_class=DNN, # passed the customized model class to the Trainer training_dataset=training_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset, collate_fn=collator_class(config), ) With the above code, we have initialized the trainer with DNN as well as RDKit datasets. However, the model is not initialized. To initialize the model, we can use trainer.initialize . trainer.initialize( d_feature = 200 # the feature dimensionality has to be the same as the output of your feature generator n_lbs = 1 # bbbp dataset has 2 label types (0, 1), but we use only 1 classification head for binary classification n_tasks = 1 # bbbp dataset has 1 tasks hidden_dims = [512, 512, 512] # 3 hidden layer, each with dimensionality 512 uncertainty_method = \"MCDropout\" # set the uncertainty method as MC Dropout ) The keyword arguments passed to trainer.initialize should be the same as what you have defined in DNN.__init__ as we use **kwargs to pass these arguments. If the keywords are different, the model may not be initialized properly. Once the trainer has been initialized, we can start the training and evaluation process as we demonstrated before. trainer.run()","title":"Initialize trainer with customized model"},{"location":"env/","text":"Environment Setup Warning Our code is developed with Python 3.10 . It does not work with Python < 3.9 . Installation MUBen is available as a Python package on PyPI and can be installed using pip. If you prefer to use MUBen as a standalone package and do not need to modify the source code, you can simply run: pip install muben Warning The muben package from PyPI does not include datasets or post-processing functions. To access these, you need to download the files manually or clone the repository. For those who wish to modify the source code or conduct experiments using the complete capabilities of MUBen, we recommend cloning the repository. You can fork the project on GitHub and clone your fork, or directly clone the original repository: # Clone your fork of the repository git clone https://github.com/<your GitHub username>/MUBen.git # Or clone the original repository with git git clone https://github.com/Yinghao-Li/MUBen.git --single-branch --branch main Anaconda Using Anaconda is the most straightforward approach to start a new virtual environment for a project. Suppose you have anaconda or miniconda installed in your local machine, you can create a new conda environment for this project using conda create . conda create -n muben python=3.10 The required packages are listed in requirements.txt . It is recommended to install these dependencies with pip install as conda install may sometimes encounter dependency resolution issue. conda activate muben pip install -r requirements.txt Docker You can also run this project within a docker container. The docker image can be built through docker build . docker build -t muben ./docker And docker run is the command to start your container in the terminal. docker run --gpus all -it --rm muben Please check the official documentation for more options. Backbone Checkpoints Some backbone models require loading pre-trained model checkpoints. For ChemBERTa, we use the DeepChem/ChemBERTa-77M-MLM checkpoint hosted on Hugging Face's Model Hub . You can specify the model name to the argument --pretrained_model_name_or_path (which is set to default), or you can download the model and pass the path to the model to the argument. The GROVER-base checkpoint is available at GROVER's project repo or can be directly downloaded through this link . Unzip the downloaded .tar.gz file to get the .pt checkpoint. The Uni-Mol checkpoint is available at Uni-Mol's project repo or can be directly downloaded through this link . The TorchMD-NET checkpoint is available at this project repo or can be directly downloaded through this link . For GROVER, Uni-Mol and TorchMD-NET, You need to specify the --checkpoint_path argument to the path to your downloaded checkpoints.","title":"Environment"},{"location":"env/#environment-setup","text":"Warning Our code is developed with Python 3.10 . It does not work with Python < 3.9 .","title":"Environment Setup"},{"location":"env/#installation","text":"MUBen is available as a Python package on PyPI and can be installed using pip. If you prefer to use MUBen as a standalone package and do not need to modify the source code, you can simply run: pip install muben Warning The muben package from PyPI does not include datasets or post-processing functions. To access these, you need to download the files manually or clone the repository. For those who wish to modify the source code or conduct experiments using the complete capabilities of MUBen, we recommend cloning the repository. You can fork the project on GitHub and clone your fork, or directly clone the original repository: # Clone your fork of the repository git clone https://github.com/<your GitHub username>/MUBen.git # Or clone the original repository with git git clone https://github.com/Yinghao-Li/MUBen.git --single-branch --branch main","title":"Installation"},{"location":"env/#anaconda","text":"Using Anaconda is the most straightforward approach to start a new virtual environment for a project. Suppose you have anaconda or miniconda installed in your local machine, you can create a new conda environment for this project using conda create . conda create -n muben python=3.10 The required packages are listed in requirements.txt . It is recommended to install these dependencies with pip install as conda install may sometimes encounter dependency resolution issue. conda activate muben pip install -r requirements.txt","title":"Anaconda"},{"location":"env/#docker","text":"You can also run this project within a docker container. The docker image can be built through docker build . docker build -t muben ./docker And docker run is the command to start your container in the terminal. docker run --gpus all -it --rm muben Please check the official documentation for more options.","title":"Docker"},{"location":"env/#backbone-checkpoints","text":"Some backbone models require loading pre-trained model checkpoints. For ChemBERTa, we use the DeepChem/ChemBERTa-77M-MLM checkpoint hosted on Hugging Face's Model Hub . You can specify the model name to the argument --pretrained_model_name_or_path (which is set to default), or you can download the model and pass the path to the model to the argument. The GROVER-base checkpoint is available at GROVER's project repo or can be directly downloaded through this link . Unzip the downloaded .tar.gz file to get the .pt checkpoint. The Uni-Mol checkpoint is available at Uni-Mol's project repo or can be directly downloaded through this link . The TorchMD-NET checkpoint is available at this project repo or can be directly downloaded through this link . For GROVER, Uni-Mol and TorchMD-NET, You need to specify the --checkpoint_path argument to the path to your downloaded checkpoints.","title":"Backbone Checkpoints"},{"location":"muben.args/","text":"module muben.args Base classes for arguments and configurations. This module defines base classes for handling arguments and configurations across the application. It includes classes for model descriptor arguments, general arguments, and configurations that encompasses dataset, model, and training settings. class DescriptorArguments Model type arguments. This class holds the arguments related to the descriptor type of the model. It allows for specifying the type of descriptor used in model construction, with options including RDKit, Linear, 2D, and 3D descriptors. Attributes: descriptor_type (str): Descriptor type. Choices are [\"RDKit\", \"Linear\", \"2D\", \"3D\"]. class Arguments Base class for managing arguments related to model training, evaluation, and data handling. This class contains many attributes. Each attribute controls a specific aspect of the training or evaluation process, including but not limited to data handling, model selection, training configurations, and evaluation metrics. Attributes: wandb_api_key (str): The API key for Weights & Biases. Default is None. wandb_project (str): The project name on Weights & Biases. Default is None. wandb_name (str): The name of the model on Weights & Biases. Default is None. disable_wandb (bool): Disable integration with Weights & Biases. Default is False. dataset_name (str): Name of the dataset. Default is an empty string. data_folder (str): Folder containing all datasets. Default is an empty string. data_seed (int): Seed used for random data splitting. Default is None. result_folder (str): Directory to save model outputs. Default is \"./output\". ignore_preprocessed_dataset (bool): Whether to ignore pre-processed datasets. Default is False. disable_dataset_saving (bool): Disable saving of pre-processed datasets. Default is False. disable_result_saving (bool): Disable saving of training results and model checkpoints. Default is False. overwrite_results (bool): Whether to overwrite existing outputs. Default is False. log_path (str): Path for the logging file. Set to disabled to disable log saving. Default is None. descriptor_type (str): Descriptor type. Choices are [\"RDKit\", \"Linear\", \"2D\", \"3D\"]. Default is None. model_name (str): Name of the model. Default is \"DNN\". Choices are defined in MODEL_NAMES. dropout (float): Dropout ratio. Default is 0.1. binary_classification_with_softmax (bool): Use softmax for binary classification. Deprecated. Default is False. regression_with_variance (bool): Use two output heads for regression (mean and variance). Default is False. retrain_model (bool): Train model from scratch regardless of existing saved models. Default is False. ignore_uncertainty_output (bool): Ignore saved uncertainty models/results. Load no-uncertainty model if possible. Default is False. ignore_no_uncertainty_output (bool): Ignore checkpoints from no-uncertainty training processes. Default is False. batch_size (int): Batch size for training. Default is 32. batch_size_inference (int): Batch size for inference. Default is None. n_epochs (int): Number of training epochs. Default is 50. lr (float): Learning rate. Default is 1e-4. grad_norm (float): Gradient norm for clipping. 0 means no clipping. Default is 0. lr_scheduler_type (str): Type of learning rate scheduler. Default is \"constant\". Choices include [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]. warmup_ratio (float): Warm-up ratio for learning rate scheduler. Default is 0.1. seed (int): Random seed for initialization. Default is 0. debug (bool): Enable debugging mode with fewer data. Default is False. deploy (bool): Enable deploy mode, avoiding runtime errors on bugs. Default is False. time_training (bool): Measure training time per training step. Default is False. freeze_backbone (bool): Freeze the backbone model during training. Only update the output layers. Default is False. valid_epoch_interval (int): Interval of training epochs between each validation step. Set to 0 to disable validation. Default is 1. valid_tolerance (int): Maximum allowed validation steps without performance increase. Default is 20. n_test (int): Number of test loops in one training process. Default is 1. For some Bayesian methods, default is 20. test_on_training_data (bool): Include test results on training data. Default is False. uncertainty_method (str): Method for uncertainty estimation. Default is UncertaintyMethods.none. Choices are defined in UncertaintyMethods. n_ensembles (int): Number of ensemble models in deep ensembles method. Default is 5. swa_lr_decay (float): Learning rate decay coefficient during SWA training. Default is 0.5. n_swa_epochs (int): Number of SWA training epochs. Default is 20. k_swa_checkpoints (int): Number of SWA checkpoints for Gaussian covariance matrix. Should not exceed n_swa_epochs . Default is 20. ts_lr (float): Learning rate for training temperature scaling parameters. Default is 0.01. n_ts_epochs (int): Number of Temperature Scaling training epochs. Default is 20. apply_temperature_scaling_after_focal_loss (bool): Apply temperature scaling after training with focal loss. Default is False. bbp_prior_sigma (float): Sigma value for Bayesian Backpropagation prior. Default is 0.1. apply_preconditioned_sgld (bool): Apply pre-conditioned Stochastic Gradient Langevin Dynamics instead of vanilla. Default is False. sgld_prior_sigma (float): Variance of the SGLD Gaussian prior. Default is 0.1. n_langevin_samples (int): Number of model checkpoints sampled from Langevin Dynamics. Default is 30. sgld_sampling_interval (int): Number of epochs per SGLD sampling operation. Default is 2. evidential_reg_loss_weight (float): Weight of evidential loss. Default is 1. evidential_clx_loss_annealing_epochs (int): Epochs before evidential loss weight increases to 1. Default is 10. no_cuda (bool): Disable CUDA even when available. Default is False. no_mps (bool): Disable Metal Performance Shaders (MPS) even when available. Default is False. num_workers (int): Number of threads for processing the dataset. Default is 0. num_preprocess_workers (int): Number of threads for preprocessing the dataset. Default is 8. pin_memory (bool): Pin memory for data loader for faster data transfer to CUDA devices. Default is False. n_feature_generating_threads (int): Number of threads for generating features. Default is 8. enable_active_learning (bool): Enable active learning. Default is False. n_init_instances (int): Number of initial instances for active learning. Default is 100. n_al_select (int): Number of instances to select in each active learning epoch. Default is 50. n_al_loops (int): Number of active learning loops. Default is 5. al_random_sampling (bool): Select instances randomly in active learning. Default is False. class Config Extended configuration class inheriting from Arguments to include dataset-specific arguments. Inherits: Arguments: Inherits all attributes from Arguments for comprehensive configuration management. Attributes: classes (List[str]): All possible classification classes. Default is None. task_type (str): Type of task, e.g., \"classification\" or \"regression\". Default is \"classification\". n_tasks (int): Number of tasks (sets of labels to predict). Default is None. eval_metric (str): Metric for evaluating validation and test performance. Default is None. random_split (bool): Whether the dataset is split randomly. Default is False. Note: The attributes defined in Config are meant to be overridden by dataset-specific metadata when used. function from_args from_args(args) Initialize configuration from an Arguments instance. This method updates the current configuration based on the values provided in an instance of the Arguments class or any subclass thereof. It's useful for transferring settings from command-line arguments or other configurations directly into this Config instance. Args: args : An instance of Arguments or a subclass containing configuration settings to be applied. Returns: Config : The instance itself, updated with the settings from args . Note: This method iterates through all attributes of args and attempts to set corresponding attributes in the Config instance. Attributes not present in Config will be ignored. function get_meta get_meta(meta_dir: str = None, meta_file_name: str = 'meta.json') Load meta file and update class attributes accordingly. Args: meta_dir (str): Directory containing the meta file. If not specified, uses data_dir attribute. meta_file_name (str): Name of the meta file to load. Default is \"meta.json\". Returns: Config : The instance itself after updating attributes based on the meta file. function load load(file_dir: str, file_name: str = 'config') Load configuration from a JSON file. Args: file_dir (str): The directory where the configuration file is located. file_name (str): The name of the file (without the extension) from which to load the configuration. Defaults to \"config\". Raises: FileNotFoundError : If the specified file does not exist or the directory does not contain the configuration file. function log log() Log the current configuration settings. Outputs the configuration settings to the logging system, formatted for easy reading. function save save(file_dir: str, file_name: str = 'config') Save the current configuration to a JSON file. Args: file_dir (str): The directory where the configuration file will be saved. file_name (str): The name of the file (without the extension) to save the configuration. Defaults to \"config\". Raises: FileNotFoundError : If the specified directory does not exist. Exception : If there is an issue saving the file. function validate validate() Validate the configuration. Checks for argument conflicts and resolves them if possible, issuing warnings for any discrepancies found. Ensures that the model name, feature type, and uncertainty methods are compatible with the specified task type. Raises: AssertionError : If an incompatible configuration is detected that cannot be automatically resolved.","title":"muben.args"},{"location":"muben.args/#module-mubenargs","text":"Base classes for arguments and configurations. This module defines base classes for handling arguments and configurations across the application. It includes classes for model descriptor arguments, general arguments, and configurations that encompasses dataset, model, and training settings.","title":"module muben.args"},{"location":"muben.args/#class-descriptorarguments","text":"Model type arguments. This class holds the arguments related to the descriptor type of the model. It allows for specifying the type of descriptor used in model construction, with options including RDKit, Linear, 2D, and 3D descriptors. Attributes: descriptor_type (str): Descriptor type. Choices are [\"RDKit\", \"Linear\", \"2D\", \"3D\"].","title":"class DescriptorArguments"},{"location":"muben.args/#class-arguments","text":"Base class for managing arguments related to model training, evaluation, and data handling. This class contains many attributes. Each attribute controls a specific aspect of the training or evaluation process, including but not limited to data handling, model selection, training configurations, and evaluation metrics. Attributes: wandb_api_key (str): The API key for Weights & Biases. Default is None. wandb_project (str): The project name on Weights & Biases. Default is None. wandb_name (str): The name of the model on Weights & Biases. Default is None. disable_wandb (bool): Disable integration with Weights & Biases. Default is False. dataset_name (str): Name of the dataset. Default is an empty string. data_folder (str): Folder containing all datasets. Default is an empty string. data_seed (int): Seed used for random data splitting. Default is None. result_folder (str): Directory to save model outputs. Default is \"./output\". ignore_preprocessed_dataset (bool): Whether to ignore pre-processed datasets. Default is False. disable_dataset_saving (bool): Disable saving of pre-processed datasets. Default is False. disable_result_saving (bool): Disable saving of training results and model checkpoints. Default is False. overwrite_results (bool): Whether to overwrite existing outputs. Default is False. log_path (str): Path for the logging file. Set to disabled to disable log saving. Default is None. descriptor_type (str): Descriptor type. Choices are [\"RDKit\", \"Linear\", \"2D\", \"3D\"]. Default is None. model_name (str): Name of the model. Default is \"DNN\". Choices are defined in MODEL_NAMES. dropout (float): Dropout ratio. Default is 0.1. binary_classification_with_softmax (bool): Use softmax for binary classification. Deprecated. Default is False. regression_with_variance (bool): Use two output heads for regression (mean and variance). Default is False. retrain_model (bool): Train model from scratch regardless of existing saved models. Default is False. ignore_uncertainty_output (bool): Ignore saved uncertainty models/results. Load no-uncertainty model if possible. Default is False. ignore_no_uncertainty_output (bool): Ignore checkpoints from no-uncertainty training processes. Default is False. batch_size (int): Batch size for training. Default is 32. batch_size_inference (int): Batch size for inference. Default is None. n_epochs (int): Number of training epochs. Default is 50. lr (float): Learning rate. Default is 1e-4. grad_norm (float): Gradient norm for clipping. 0 means no clipping. Default is 0. lr_scheduler_type (str): Type of learning rate scheduler. Default is \"constant\". Choices include [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]. warmup_ratio (float): Warm-up ratio for learning rate scheduler. Default is 0.1. seed (int): Random seed for initialization. Default is 0. debug (bool): Enable debugging mode with fewer data. Default is False. deploy (bool): Enable deploy mode, avoiding runtime errors on bugs. Default is False. time_training (bool): Measure training time per training step. Default is False. freeze_backbone (bool): Freeze the backbone model during training. Only update the output layers. Default is False. valid_epoch_interval (int): Interval of training epochs between each validation step. Set to 0 to disable validation. Default is 1. valid_tolerance (int): Maximum allowed validation steps without performance increase. Default is 20. n_test (int): Number of test loops in one training process. Default is 1. For some Bayesian methods, default is 20. test_on_training_data (bool): Include test results on training data. Default is False. uncertainty_method (str): Method for uncertainty estimation. Default is UncertaintyMethods.none. Choices are defined in UncertaintyMethods. n_ensembles (int): Number of ensemble models in deep ensembles method. Default is 5. swa_lr_decay (float): Learning rate decay coefficient during SWA training. Default is 0.5. n_swa_epochs (int): Number of SWA training epochs. Default is 20. k_swa_checkpoints (int): Number of SWA checkpoints for Gaussian covariance matrix. Should not exceed n_swa_epochs . Default is 20. ts_lr (float): Learning rate for training temperature scaling parameters. Default is 0.01. n_ts_epochs (int): Number of Temperature Scaling training epochs. Default is 20. apply_temperature_scaling_after_focal_loss (bool): Apply temperature scaling after training with focal loss. Default is False. bbp_prior_sigma (float): Sigma value for Bayesian Backpropagation prior. Default is 0.1. apply_preconditioned_sgld (bool): Apply pre-conditioned Stochastic Gradient Langevin Dynamics instead of vanilla. Default is False. sgld_prior_sigma (float): Variance of the SGLD Gaussian prior. Default is 0.1. n_langevin_samples (int): Number of model checkpoints sampled from Langevin Dynamics. Default is 30. sgld_sampling_interval (int): Number of epochs per SGLD sampling operation. Default is 2. evidential_reg_loss_weight (float): Weight of evidential loss. Default is 1. evidential_clx_loss_annealing_epochs (int): Epochs before evidential loss weight increases to 1. Default is 10. no_cuda (bool): Disable CUDA even when available. Default is False. no_mps (bool): Disable Metal Performance Shaders (MPS) even when available. Default is False. num_workers (int): Number of threads for processing the dataset. Default is 0. num_preprocess_workers (int): Number of threads for preprocessing the dataset. Default is 8. pin_memory (bool): Pin memory for data loader for faster data transfer to CUDA devices. Default is False. n_feature_generating_threads (int): Number of threads for generating features. Default is 8. enable_active_learning (bool): Enable active learning. Default is False. n_init_instances (int): Number of initial instances for active learning. Default is 100. n_al_select (int): Number of instances to select in each active learning epoch. Default is 50. n_al_loops (int): Number of active learning loops. Default is 5. al_random_sampling (bool): Select instances randomly in active learning. Default is False.","title":"class Arguments"},{"location":"muben.args/#class-config","text":"Extended configuration class inheriting from Arguments to include dataset-specific arguments. Inherits: Arguments: Inherits all attributes from Arguments for comprehensive configuration management. Attributes: classes (List[str]): All possible classification classes. Default is None. task_type (str): Type of task, e.g., \"classification\" or \"regression\". Default is \"classification\". n_tasks (int): Number of tasks (sets of labels to predict). Default is None. eval_metric (str): Metric for evaluating validation and test performance. Default is None. random_split (bool): Whether the dataset is split randomly. Default is False. Note: The attributes defined in Config are meant to be overridden by dataset-specific metadata when used.","title":"class Config"},{"location":"muben.args/#function-from_args","text":"from_args(args) Initialize configuration from an Arguments instance. This method updates the current configuration based on the values provided in an instance of the Arguments class or any subclass thereof. It's useful for transferring settings from command-line arguments or other configurations directly into this Config instance. Args: args : An instance of Arguments or a subclass containing configuration settings to be applied. Returns: Config : The instance itself, updated with the settings from args . Note: This method iterates through all attributes of args and attempts to set corresponding attributes in the Config instance. Attributes not present in Config will be ignored.","title":"function from_args"},{"location":"muben.args/#function-get_meta","text":"get_meta(meta_dir: str = None, meta_file_name: str = 'meta.json') Load meta file and update class attributes accordingly. Args: meta_dir (str): Directory containing the meta file. If not specified, uses data_dir attribute. meta_file_name (str): Name of the meta file to load. Default is \"meta.json\". Returns: Config : The instance itself after updating attributes based on the meta file.","title":"function get_meta"},{"location":"muben.args/#function-load","text":"load(file_dir: str, file_name: str = 'config') Load configuration from a JSON file. Args: file_dir (str): The directory where the configuration file is located. file_name (str): The name of the file (without the extension) from which to load the configuration. Defaults to \"config\". Raises: FileNotFoundError : If the specified file does not exist or the directory does not contain the configuration file.","title":"function load"},{"location":"muben.args/#function-log","text":"log() Log the current configuration settings. Outputs the configuration settings to the logging system, formatted for easy reading.","title":"function log"},{"location":"muben.args/#function-save","text":"save(file_dir: str, file_name: str = 'config') Save the current configuration to a JSON file. Args: file_dir (str): The directory where the configuration file will be saved. file_name (str): The name of the file (without the extension) to save the configuration. Defaults to \"config\". Raises: FileNotFoundError : If the specified directory does not exist. Exception : If there is an issue saving the file.","title":"function save"},{"location":"muben.args/#function-validate","text":"validate() Validate the configuration. Checks for argument conflicts and resolves them if possible, issuing warnings for any discrepancies found. Ensures that the model name, feature type, and uncertainty methods are compatible with the specified task type. Raises: AssertionError : If an incompatible configuration is detected that cannot be automatically resolved.","title":"function validate"},{"location":"muben.dataset/","text":"module muben.dataset This module includes base classes for dataset creation and batch processing. function pack_instances pack_instances(**kwargs) \u2192 list[dict] Converts lists of attributes into a list of data instances. Each data instance is represented as a dictionary with attribute names as keys and the corresponding data point values as values. Args: **kwargs : Variable length keyword arguments, where each key is an attribute name and its value is a list of data points. Returns: List[Dict] : A list of dictionaries, each representing a data instance. function unpack_instances unpack_instances(instance_list: list[dict], attr_names: list[str] = None) Converts a list of dictionaries (data instances) back into lists of attribute values. This function is essentially the inverse of pack_instances . Args: instance_list (List[Dict]): A list of data instances, where each instance is a dictionary with attribute names as keys. attr_names ([List[str]], optional): A list of attribute names to extract. If not provided, all attributes found in the first instance are used. Returns: List[List] : A list of lists, where each sublist contains all values for a particular attribute across all instances. class Batch Represents a batch of data instances, where each instance is initialized with attributes provided as keyword arguments. Each attribute name acts as a key to its corresponding value, allowing for flexible data handling within a batched context. Attributes: size (int): The size of the batch. Defaults to 0. _tensor_members (dict): A dictionary to keep track of tensor attributes for device transfer operations. function __init__ __init__(**kwargs) Initializes a Batch object with dynamic attributes based on the provided keyword arguments. Args: **kwargs : Arbitrary keyword arguments representing attributes of data instances within the batch. A special keyword 'batch_size' can be used to explicitly set the batch size. function to to(device) Moves all tensor attributes to the specified device (cpu, cuda). Args: device : The target device to move the tensor attributes to. Returns: self : The batch instance with its tensor attributes moved to the specified device. class Dataset Custom Dataset class to handle data storage, manipulation, and preprocessing operations. Attributes: _smiles (Union[list[str], None]): Chemical structures represented as strings. _lbs (Union[np.ndarray, None]): data labels. _masks (Union[np.ndarray, None]): Data masks. _ori_ids (Union[np.ndarray, None]): Original IDs of the datapoints, specifically used for randomly split datasets. data_instances : Packed instances of data. property data_instances Returns the current data instances, considering whether the full dataset or a selection is being used. property lbs Returns the label data, considering whether standardized labels are being used. property smiles Returns the chemical structures represented as strings. function add_sample_by_ids add_sample_by_ids(ids: list[int] = None) Appends a subset of data instances to the selected data instances. Args: ids (list[int], optional): Indices of the selected instances. Raises: ValueError : If ids is not specified. Returns: self (Dataset): The dataset with the added data instances. function create_features create_features(config) Creates data features. This method should be implemented by subclasses to generate data features according to different descriptors or fingerprints. Raises: NotImplementedError : This method should be implemented by subclasses. function downsample_by downsample_by(file_path: str = None, ids: list[int] = None) Downsamples the dataset to a subset with the specified indices. Args: file_path (str, optional): Path to the file containing the indices of the selected instances. ids (list[int], optional): Indices of the selected instances. Raises: ValueError : If neither ids nor file_path is specified. Returns: self (Dataset): The downsampled dataset. function get_instances get_instances() Gets the instances of the dataset. This method should be implemented by subclasses to pack data, labels, and masks into data instances. Raises: NotImplementedError : This method should be implemented by subclasses. function load load(file_path: str) Loads the entire dataset from disk. Args: file_path (str): Path to the saved file. Returns: self (Dataset) function prepare prepare(config, partition, **kwargs) Prepares the dataset for training and testing. Args: config : Configuration parameters. partition (str): The dataset partition; should be one of 'train', 'valid', 'test'. Raises: ValueError : If partition is not one of 'train', 'valid', 'test'. Returns: self (Dataset): The prepared dataset. function read_csv read_csv(data_dir: str, partition: str) Reads data from CSV files. Args: data_dir (str): The directory where data files are stored. partition (str): The dataset partition ('train', 'valid', 'test'). Raises: FileNotFoundError : If the specified file does not exist. Returns: self (Dataset) function save save(file_path: str) Saves the entire dataset for future use. Args: file_path (str): Path to the save file. Returns: self (Dataset) function set_standardized_lbs set_standardized_lbs(lbs) Sets standardized labels and updates the instance list accordingly. Args: lbs : The standardized label data. Returns: self (Dataset): The dataset with the standardized labels set. function toggle_standardized_lbs toggle_standardized_lbs(use_standardized_lbs: bool = None) Toggle between using standardized and unstandardized labels. Args: use_standardized_lbs (bool, optional): Whether to use standardized labels. Defaults to None. Returns: self (Dataset): The dataset with the standardized labels toggled. function update_lbs update_lbs(lbs) Updates the dataset labels and the instance list accordingly. Args: lbs : The new labels. Returns: self (Dataset): The dataset with the updated labels.","title":"muben.dataset"},{"location":"muben.dataset/#module-mubendataset","text":"This module includes base classes for dataset creation and batch processing.","title":"module muben.dataset"},{"location":"muben.dataset/#function-pack_instances","text":"pack_instances(**kwargs) \u2192 list[dict] Converts lists of attributes into a list of data instances. Each data instance is represented as a dictionary with attribute names as keys and the corresponding data point values as values. Args: **kwargs : Variable length keyword arguments, where each key is an attribute name and its value is a list of data points. Returns: List[Dict] : A list of dictionaries, each representing a data instance.","title":"function pack_instances"},{"location":"muben.dataset/#function-unpack_instances","text":"unpack_instances(instance_list: list[dict], attr_names: list[str] = None) Converts a list of dictionaries (data instances) back into lists of attribute values. This function is essentially the inverse of pack_instances . Args: instance_list (List[Dict]): A list of data instances, where each instance is a dictionary with attribute names as keys. attr_names ([List[str]], optional): A list of attribute names to extract. If not provided, all attributes found in the first instance are used. Returns: List[List] : A list of lists, where each sublist contains all values for a particular attribute across all instances.","title":"function unpack_instances"},{"location":"muben.dataset/#class-batch","text":"Represents a batch of data instances, where each instance is initialized with attributes provided as keyword arguments. Each attribute name acts as a key to its corresponding value, allowing for flexible data handling within a batched context. Attributes: size (int): The size of the batch. Defaults to 0. _tensor_members (dict): A dictionary to keep track of tensor attributes for device transfer operations.","title":"class Batch"},{"location":"muben.dataset/#function-__init__","text":"__init__(**kwargs) Initializes a Batch object with dynamic attributes based on the provided keyword arguments. Args: **kwargs : Arbitrary keyword arguments representing attributes of data instances within the batch. A special keyword 'batch_size' can be used to explicitly set the batch size.","title":"function __init__"},{"location":"muben.dataset/#function-to","text":"to(device) Moves all tensor attributes to the specified device (cpu, cuda). Args: device : The target device to move the tensor attributes to. Returns: self : The batch instance with its tensor attributes moved to the specified device.","title":"function to"},{"location":"muben.dataset/#class-dataset","text":"Custom Dataset class to handle data storage, manipulation, and preprocessing operations. Attributes: _smiles (Union[list[str], None]): Chemical structures represented as strings. _lbs (Union[np.ndarray, None]): data labels. _masks (Union[np.ndarray, None]): Data masks. _ori_ids (Union[np.ndarray, None]): Original IDs of the datapoints, specifically used for randomly split datasets. data_instances : Packed instances of data.","title":"class Dataset"},{"location":"muben.dataset/#property-data_instances","text":"Returns the current data instances, considering whether the full dataset or a selection is being used.","title":"property data_instances"},{"location":"muben.dataset/#property-lbs","text":"Returns the label data, considering whether standardized labels are being used.","title":"property lbs"},{"location":"muben.dataset/#property-smiles","text":"Returns the chemical structures represented as strings.","title":"property smiles"},{"location":"muben.dataset/#function-add_sample_by_ids","text":"add_sample_by_ids(ids: list[int] = None) Appends a subset of data instances to the selected data instances. Args: ids (list[int], optional): Indices of the selected instances. Raises: ValueError : If ids is not specified. Returns: self (Dataset): The dataset with the added data instances.","title":"function add_sample_by_ids"},{"location":"muben.dataset/#function-create_features","text":"create_features(config) Creates data features. This method should be implemented by subclasses to generate data features according to different descriptors or fingerprints. Raises: NotImplementedError : This method should be implemented by subclasses.","title":"function create_features"},{"location":"muben.dataset/#function-downsample_by","text":"downsample_by(file_path: str = None, ids: list[int] = None) Downsamples the dataset to a subset with the specified indices. Args: file_path (str, optional): Path to the file containing the indices of the selected instances. ids (list[int], optional): Indices of the selected instances. Raises: ValueError : If neither ids nor file_path is specified. Returns: self (Dataset): The downsampled dataset.","title":"function downsample_by"},{"location":"muben.dataset/#function-get_instances","text":"get_instances() Gets the instances of the dataset. This method should be implemented by subclasses to pack data, labels, and masks into data instances. Raises: NotImplementedError : This method should be implemented by subclasses.","title":"function get_instances"},{"location":"muben.dataset/#function-load","text":"load(file_path: str) Loads the entire dataset from disk. Args: file_path (str): Path to the saved file. Returns: self (Dataset)","title":"function load"},{"location":"muben.dataset/#function-prepare","text":"prepare(config, partition, **kwargs) Prepares the dataset for training and testing. Args: config : Configuration parameters. partition (str): The dataset partition; should be one of 'train', 'valid', 'test'. Raises: ValueError : If partition is not one of 'train', 'valid', 'test'. Returns: self (Dataset): The prepared dataset.","title":"function prepare"},{"location":"muben.dataset/#function-read_csv","text":"read_csv(data_dir: str, partition: str) Reads data from CSV files. Args: data_dir (str): The directory where data files are stored. partition (str): The dataset partition ('train', 'valid', 'test'). Raises: FileNotFoundError : If the specified file does not exist. Returns: self (Dataset)","title":"function read_csv"},{"location":"muben.dataset/#function-save","text":"save(file_path: str) Saves the entire dataset for future use. Args: file_path (str): Path to the save file. Returns: self (Dataset)","title":"function save"},{"location":"muben.dataset/#function-set_standardized_lbs","text":"set_standardized_lbs(lbs) Sets standardized labels and updates the instance list accordingly. Args: lbs : The standardized label data. Returns: self (Dataset): The dataset with the standardized labels set.","title":"function set_standardized_lbs"},{"location":"muben.dataset/#function-toggle_standardized_lbs","text":"toggle_standardized_lbs(use_standardized_lbs: bool = None) Toggle between using standardized and unstandardized labels. Args: use_standardized_lbs (bool, optional): Whether to use standardized labels. Defaults to None. Returns: self (Dataset): The dataset with the standardized labels toggled.","title":"function toggle_standardized_lbs"},{"location":"muben.dataset/#function-update_lbs","text":"update_lbs(lbs) Updates the dataset labels and the instance list accordingly. Args: lbs : The new labels. Returns: self (Dataset): The dataset with the updated labels.","title":"function update_lbs"},{"location":"muben.layers/","text":"module muben.layers Versatile Output Layer for Backbone Models This module implements an output layer that can be applied to various backbone models. It provides the option of utilizing different uncertainty methods for model's output and supports both classification and regression tasks. class OutputLayer Customizable output layer for various backbone models. This class provides an interface to add an output layer with or without uncertainty methods to various backbone models. It supports both classification and regression tasks and allows for the introduction of uncertainty into the model's output. Args: last_hidden_dim (int): Dimensionality of the last hidden state from the backbone model. n_output_heads (int): Number of output heads (e.g., number of classes for classification). uncertainty_method (str, optional): Method to introduce uncertainty in the output layer. Available methods are defined in UncertaintyMethods. Defaults to UncertaintyMethods.none. task_type (str, optional): Type of task - \"classification\" or \"regression\". Defaults to \"classification\". **kwargs : Additional keyword arguments to be passed to the specific output layers. Attributes: _uncertainty_method (str): The uncertainty method used in the output layer. _task_type (str): The type of task the model is configured for (classification or regression). output_layer (nn.Module): The specific output layer instance used in the model. kld (Optional[torch.Tensor]): Kullback-Leibler Divergence for Bayesian methods, if applicable. function __init__ __init__( last_hidden_dim, n_output_heads, uncertainty_method='none', task_type='classification', **kwargs ) Initializes the OutputLayer instance. Args: last_hidden_dim (int): Dimensionality of the last hidden state from the backbone model. n_output_heads (int): Number of output heads (e.g., number of classes for classification). uncertainty_method (str, optional): Method to introduce uncertainty in the output layer. Available methods are defined in UncertaintyMethods. Defaults to UncertaintyMethods.none. task_type (str, optional): Type of task - \"classification\" or \"regression\". Defaults to \"classification\". **kwargs : Additional keyword arguments to be passed to the specific output layers. function forward forward(x: Tensor, **kwargs) \u2192 Tensor Forward pass of the output layer. Args: x (torch.Tensor): Input tensor for the output layer. Returns: torch.Tensor : The output logits or values of the model. function initialize initialize() \u2192 OutputLayer Initializes the weights of the output layer. Different initializations are applied based on the uncertainty method and task type. Returns: OutputLayer : The initialized model instance.","title":"muben.layers"},{"location":"muben.layers/#module-mubenlayers","text":"Versatile Output Layer for Backbone Models This module implements an output layer that can be applied to various backbone models. It provides the option of utilizing different uncertainty methods for model's output and supports both classification and regression tasks.","title":"module muben.layers"},{"location":"muben.layers/#class-outputlayer","text":"Customizable output layer for various backbone models. This class provides an interface to add an output layer with or without uncertainty methods to various backbone models. It supports both classification and regression tasks and allows for the introduction of uncertainty into the model's output. Args: last_hidden_dim (int): Dimensionality of the last hidden state from the backbone model. n_output_heads (int): Number of output heads (e.g., number of classes for classification). uncertainty_method (str, optional): Method to introduce uncertainty in the output layer. Available methods are defined in UncertaintyMethods. Defaults to UncertaintyMethods.none. task_type (str, optional): Type of task - \"classification\" or \"regression\". Defaults to \"classification\". **kwargs : Additional keyword arguments to be passed to the specific output layers. Attributes: _uncertainty_method (str): The uncertainty method used in the output layer. _task_type (str): The type of task the model is configured for (classification or regression). output_layer (nn.Module): The specific output layer instance used in the model. kld (Optional[torch.Tensor]): Kullback-Leibler Divergence for Bayesian methods, if applicable.","title":"class OutputLayer"},{"location":"muben.layers/#function-__init__","text":"__init__( last_hidden_dim, n_output_heads, uncertainty_method='none', task_type='classification', **kwargs ) Initializes the OutputLayer instance. Args: last_hidden_dim (int): Dimensionality of the last hidden state from the backbone model. n_output_heads (int): Number of output heads (e.g., number of classes for classification). uncertainty_method (str, optional): Method to introduce uncertainty in the output layer. Available methods are defined in UncertaintyMethods. Defaults to UncertaintyMethods.none. task_type (str, optional): Type of task - \"classification\" or \"regression\". Defaults to \"classification\". **kwargs : Additional keyword arguments to be passed to the specific output layers.","title":"function __init__"},{"location":"muben.layers/#function-forward","text":"forward(x: Tensor, **kwargs) \u2192 Tensor Forward pass of the output layer. Args: x (torch.Tensor): Input tensor for the output layer. Returns: torch.Tensor : The output logits or values of the model.","title":"function forward"},{"location":"muben.layers/#function-initialize","text":"initialize() \u2192 OutputLayer Initializes the weights of the output layer. Different initializations are applied based on the uncertainty method and task type. Returns: OutputLayer : The initialized model instance.","title":"function initialize"},{"location":"muben.train/","text":"module muben.train Base trainer functions to facilitate training, validation, and testing of machine learning models. This Trainer class is designed to seamlessly integrate with various datasets, loss functions, metrics, and uncertainty estimation methods. It provides convenient mechanisms to standardize, initialize and manage training states, and is also integrated with logging and Weights & Biases (wandb) for experiment tracking. class Trainer This Trainer class is designed to facilitate the training, validation, and testing of machine learning models. It integrates with various datasets, loss functions, metrics, and uncertainty estimation methods, providing mechanisms to standardize, initialize, and manage training states. It supports logging and integration with Weights & Biases (wandb) for experiment tracking. method __init__ __init__( config, model_class=None, training_dataset=None, valid_dataset=None, test_dataset=None, collate_fn=None, scalar=None, **kwargs ) Initializes the Trainer object. Args: config (Config): Configuration object containing all necessary parameters for training. model_class (optional): The class of the model to be trained. training_dataset (Dataset, optional): Dataset for training the model. valid_dataset (Dataset, optional): Dataset for validating the model. test_dataset (Dataset, optional): Dataset for testing the model. collate_fn (Callable, optional): Function to collate data samples into batches. scalar (StandardScaler, optional): Scaler for standardizing input data. **kwargs : Additional keyword arguments for configuration adjustments. property backbone_params Retrieves parameters of the model's backbone, excluding the output layer. Useful for operations that need to differentiate between backbone and output layer parameters, such as freezing the backbone during training. Returns: list : Parameters of the model's backbone. property config Retrieves the configuration of the Trainer. property model Retrieves the scaled model if available, otherwise returns the base model. property n_model_parameters Computes the total number of trainable parameters in the model. property n_training_steps The number of total training steps property n_update_steps_per_epoch Calculates the number of update steps required per epoch. Returns: int : Number of update steps per epoch. property n_valid_steps The number of total validation steps property test_dataset property training_dataset property valid_dataset method eval_and_save eval_and_save() Evaluates the model's performance on the validation dataset and saves it if its performance is improved. This method is part of the training loop where the model is periodically evaluated on the validation dataset, and the best-performing model state is saved. method evaluate evaluate( dataset, n_run: Optional[int] = 1, return_preds: Optional[bool] = False ) Evaluates the model's performance on the given dataset. Args: dataset (Dataset): The dataset to evaluate the model on. n_run (int, optional): Number of runs for evaluation. Defaults to 1. return_preds (bool, optional): Whether to return the predictions along with metrics. Defaults to False. Returns: dict, or (dict, numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray]) : Evaluation metrics, or tuple containing metrics and predictions based on return_preds . method freeze freeze() Freezes all model parameters, preventing them from being updated during training. Returns: Trainer : The current instance with model parameters frozen. method freeze_backbone freeze_backbone() Freezes the backbone parameters of the model, preventing them from being updated during training. Returns: Trainer : The current instance with backbone parameters frozen. method get_dataloader get_dataloader( dataset, shuffle: Optional[bool] = False, batch_size: Optional[int] = 0 ) Creates a DataLoader for the specified dataset. Args: dataset : Dataset for which the DataLoader is to be created. shuffle (bool, optional): Whether to shuffle the data. Defaults to False. batch_size (int, optional): Batch size for the DataLoader. Uses the batch size from the configuration if not specified. Returns: DataLoader : The created DataLoader for the provided dataset. method get_loss get_loss(logits, batch, n_steps_per_epoch=None) \u2192 Tensor Computes the loss for a batch of data. This method can be overridden by subclasses to implement custom loss computation logic. Args: logits (torch.Tensor): The predictions or logits produced by the model for the given batch. batch (Batch): The batch of training data. n_steps_per_epoch (int, optional): Represents the number of batches in a training epoch, used specifically for certain uncertainty methods like Bayesian Backpropagation (BBP). Returns: torch.Tensor : The computed loss for the batch. method get_metrics get_metrics(lbs, preds, masks) Calculates evaluation metrics based on the given labels, predictions, and masks. This method computes the appropriate metrics based on the task type (classification or regression). Args: lbs (numpy.ndarray): Ground truth labels. preds (numpy.ndarray): Model predictions. masks (numpy.ndarray): Masks indicating valid entries in labels and predictions. Returns: dict : Computed metrics for evaluation. method inference inference(dataset, **kwargs) Conducts inference over an entire dataset using the model. Args: dataset (Dataset): The dataset for which inference needs to be performed. **kwargs : Additional keyword arguments. Returns: numpy.ndarray : The model outputs as logits or a tuple of logits. method initialize initialize(*args, **kwargs) Initializes the trainer's status and its key components including the model, optimizer, learning rate scheduler, and loss function. This method sets up the training environment by initializing the model, optimizer, learning rate scheduler, and the loss function based on the provided configuration. It also prepares the trainer for logging and checkpointing mechanisms. Args: *args : Variable length argument list for model initialization. **kwargs : Arbitrary keyword arguments for model initialization. Returns: Trainer : The initialized Trainer instance ready for training. method initialize_loss initialize_loss(disable_focal_loss=False) Initializes the loss function based on the task type and specified uncertainty method. This method sets up the appropriate loss function for the training process, considering the task type (classification or regression) and whether any specific uncertainty methods (e.g., evidential or focal loss) are applied. Args: disable_focal_loss (bool, optional): If True, disables the use of focal loss, even if specified by the uncertainty method. Defaults to False. Returns: Trainer : The Trainer instance with the initialized loss function. method initialize_model initialize_model(*args, **kwargs) Abstract method to initialize the model. This method should be implemented in subclasses of Trainer, providing the specific logic to initialize the model that will be used for training. Returns: Trainer : The Trainer instance with the model initialized. method initialize_optimizer initialize_optimizer(*args, **kwargs) Initializes the model's optimizer based on the set configurations. This method sets up the optimizer for the model's parameters. It includes special handling for SGLD-based uncertainty methods by differentiating between backbone and output layer parameters. Args: *args : Variable length argument list for optimizer initialization. **kwargs : Arbitrary keyword arguments for optimizer initialization. Returns: Trainer : The Trainer instance with the initialized optimizer. method initialize_scheduler initialize_scheduler() Initializes the learning rate scheduler based on the training configuration. This method sets up the learning rate scheduler using the total number of training steps and the specified warmup ratio. Returns: Trainer : The Trainer instance with the initialized scheduler. method inverse_standardize_preds inverse_standardize_preds( preds: Union[ndarray, Tuple[ndarray, ndarray]] ) \u2192 Union[ndarray, Tuple[ndarray, ndarray]] Transforms predictions back to their original scale if they have been standardized. Args: preds (numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray]): Model predictions, can either be a single array or a tuple containing two arrays for mean and variance, respectively. Returns: numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray] : Inverse-standardized predictions. method load_checkpoint load_checkpoint() Loads the model from a checkpoint. This method attempts to load the model checkpoint from the configured path. It supports loading with and without considering the uncertainty estimation method used during training. Returns: bool : True if the model is successfully loaded from a checkpoint, otherwise False. method log_results log_results( metrics: dict, logging_func=<bound method Logger.info of <Logger trainer.trainer (WARNING)>> ) Logs evaluation metrics using the specified logging function. Args: metrics (dict): Dictionary containing evaluation metrics to be logged. logging_func (function, optional): Logging function to which metrics will be sent. Defaults to logger.info . Returns: None method process_logits process_logits(logits: ndarray) \u2192 Union[ndarray, Tuple[ndarray, ndarray]] Processes the output logits based on the training tasks or variants. Args: logits (numpy.ndarray): The raw logits produced by the model. Returns: numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray] : Processed logits or a tuple containing processed logits based on the task type. method run run() Executes the training and evaluation process. This method serves as the main entry point for the training process, orchestrating the execution based on the specified uncertainty method. It handles different training strategies like ensembles, SWAG, temperature scaling, and more. Returns: None method run_ensembles run_ensembles() Trains and evaluates an ensemble of models. This method is used for uncertainty estimation through model ensembles, training multiple models with different seeds and evaluating their collective performance. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method run_focal_loss run_focal_loss() Runs the training and evaluation pipeline utilizing focal loss. Focal loss is used to address class imbalance by focusing more on hard-to-classify examples. Temperature scaling can optionally be applied after training with focal loss. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method run_iso_calibration run_iso_calibration() Performs isotonic calibration. Isotonic calibration is applied to calibrate the uncertainties of the model's predictions, based on the approach described in 'Accurate Uncertainties for Deep Learning Using Calibrated Regression'. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method run_sgld run_sgld() Executes training and evaluation with Stochastic Gradient Langevin Dynamics (SGLD). SGLD is used for uncertainty estimation, incorporating random noise into the gradients to explore the model's parameter space more broadly. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method run_single_shot run_single_shot(apply_test=True) Runs the training and evaluation pipeline for a single iteration. This method handles the process of training the model and optionally evaluating it on a test dataset. It is designed for a straightforward, single iteration of training and testing. Args: apply_test (bool, optional): Whether to run the test function as part of the process. Defaults to True. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method run_swag run_swag() Executes the training and evaluation pipeline using the SWAG method. Stochastic Weight Averaging Gaussian (SWAG) is used for uncertainty estimation. This method involves training the model with early stopping and applying SWAG for post-training uncertainty estimation. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method run_temperature_scaling run_temperature_scaling() Executes the training and evaluation pipeline with temperature scaling. Temperature scaling is applied as a post-processing step to calibrate the confidence of the model's predictions. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method save_checkpoint save_checkpoint() Saves the current model state as a checkpoint. This method checks the disable_result_saving configuration flag before saving. If saving is disabled, it logs a warning and does not perform the save operation. Returns: Trainer : The current instance after attempting to save the model checkpoint. method save_results save_results(path, preds, variances, lbs, masks) Saves the model predictions, variances, ground truth labels, and masks to disk. This method saves the results of model predictions to a specified path. It is capable of handling both the predictions and their associated variances, along with the ground truth labels and masks that indicate which data points should be considered in the analysis. If the configuration flag disable_result_saving is set to True, the method will log a warning and not perform any saving operation. Args: path (str): The destination path where the results will be saved. preds (array_like): The predictions generated by the model. variances (array_like): The variances associated with each prediction, indicating the uncertainty of the predictions. lbs (array_like): The ground truth labels against which the model's predictions can be evaluated. masks (array_like): Masks indicating which data points are valid and should be considered in the evaluation. Returns: None : This method does not return any value. method set_mode set_mode(mode: str) Sets the training mode for the model. Depending on the mode, the model is set to training, evaluation, or testing. This method is essential for correctly configuring the model's state for different phases of the training and evaluation process. Args: mode (str): The mode to set the model to. Should be one of 'train', 'eval', or 'test'. Returns: Trainer : The Trainer instance with the model set to the specified mode. method standardize_training_lbs standardize_training_lbs() Standardizes the label distribution of the training dataset for regression tasks. This method applies standardization to the labels of the training dataset, transforming them to a standard Gaussian distribution. It's applicable only for regression tasks. Returns: Trainer : The Trainer instance with standardized training labels. method swa_session swa_session() Executes the SWA session. This method is intended to be overridden by child classes for specialized handling of optimizer or model initialization required by SWA (Stochastic Weight Averaging). Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method test test(load_best_model=True, return_preds=False) Tests the model's performance on the test dataset. Args: load_best_model (bool, optional): Whether to load the best model saved during training for testing. Defaults to True. return_preds (bool, optional): Whether to return the predictions along with metrics. Defaults to False. Returns: dict, or tuple[dict, numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray]] : Evaluation metrics (and predictions) for the test dataset. method test_on_training_data test_on_training_data( load_best_model=True, return_preds=False, disable_result_saving=False ) Tests the model's performance on the training dataset. This method is useful for understanding the model's performance on the data it was trained on, which can provide insights into overfitting or underfitting. Args: load_best_model (bool, optional): If True, loads the best model saved during training. Defaults to True. return_preds (bool, optional): If True, returns the predictions along with the evaluation metrics. Defaults to False. disable_result_saving (bool, optional): If True, disables saving the results to disk. Defaults to False. Returns: dict, or tuple[dict, numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray]] : Evaluation metrics, or a tuple containing metrics and predictions if return_preds is True. method train train(use_valid_dataset=False) Executes the training process for the model. Optionally allows for training using the validation dataset instead of the training dataset. This option can be useful for certain model calibration techniques like temperature scaling. Args: use_valid_dataset (bool, optional): Determines if the validation dataset should be used for training instead of the training dataset. Defaults to False. Returns: None : This method returns None. method training_epoch training_epoch(data_loader) Performs a single epoch of training using the provided data loader. This method iterates over the data loader, performs the forward pass, computes the loss, and updates the model parameters. Args: data_loader (DataLoader): DataLoader object providing batches of training data. Returns: float : The average training loss for the epoch. method ts_session ts_session() Executes the temperature scaling session. This session involves retraining the model on the validation set with a modified learning rate and epochs to apply temperature scaling for model calibration. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining. method unfreeze unfreeze() Unfreezes all model parameters, allowing them to be updated during training. Returns: Trainer : The current instance with model parameters unfrozen. method unfreeze_backbone unfreeze_backbone() Unfreezes the backbone parameters of the model, allowing them to be updated during training. Returns: Trainer : The current instance with backbone parameters unfrozen.","title":"muben.train"},{"location":"muben.train/#module-mubentrain","text":"Base trainer functions to facilitate training, validation, and testing of machine learning models. This Trainer class is designed to seamlessly integrate with various datasets, loss functions, metrics, and uncertainty estimation methods. It provides convenient mechanisms to standardize, initialize and manage training states, and is also integrated with logging and Weights & Biases (wandb) for experiment tracking.","title":"module muben.train"},{"location":"muben.train/#class-trainer","text":"This Trainer class is designed to facilitate the training, validation, and testing of machine learning models. It integrates with various datasets, loss functions, metrics, and uncertainty estimation methods, providing mechanisms to standardize, initialize, and manage training states. It supports logging and integration with Weights & Biases (wandb) for experiment tracking.","title":"class Trainer"},{"location":"muben.train/#method-__init__","text":"__init__( config, model_class=None, training_dataset=None, valid_dataset=None, test_dataset=None, collate_fn=None, scalar=None, **kwargs ) Initializes the Trainer object. Args: config (Config): Configuration object containing all necessary parameters for training. model_class (optional): The class of the model to be trained. training_dataset (Dataset, optional): Dataset for training the model. valid_dataset (Dataset, optional): Dataset for validating the model. test_dataset (Dataset, optional): Dataset for testing the model. collate_fn (Callable, optional): Function to collate data samples into batches. scalar (StandardScaler, optional): Scaler for standardizing input data. **kwargs : Additional keyword arguments for configuration adjustments.","title":"method __init__"},{"location":"muben.train/#property-backbone_params","text":"Retrieves parameters of the model's backbone, excluding the output layer. Useful for operations that need to differentiate between backbone and output layer parameters, such as freezing the backbone during training. Returns: list : Parameters of the model's backbone.","title":"property backbone_params"},{"location":"muben.train/#property-config","text":"Retrieves the configuration of the Trainer.","title":"property config"},{"location":"muben.train/#property-model","text":"Retrieves the scaled model if available, otherwise returns the base model.","title":"property model"},{"location":"muben.train/#property-n_model_parameters","text":"Computes the total number of trainable parameters in the model.","title":"property n_model_parameters"},{"location":"muben.train/#property-n_training_steps","text":"The number of total training steps","title":"property n_training_steps"},{"location":"muben.train/#property-n_update_steps_per_epoch","text":"Calculates the number of update steps required per epoch. Returns: int : Number of update steps per epoch.","title":"property n_update_steps_per_epoch"},{"location":"muben.train/#property-n_valid_steps","text":"The number of total validation steps","title":"property n_valid_steps"},{"location":"muben.train/#property-test_dataset","text":"","title":"property test_dataset"},{"location":"muben.train/#property-training_dataset","text":"","title":"property training_dataset"},{"location":"muben.train/#property-valid_dataset","text":"","title":"property valid_dataset"},{"location":"muben.train/#method-eval_and_save","text":"eval_and_save() Evaluates the model's performance on the validation dataset and saves it if its performance is improved. This method is part of the training loop where the model is periodically evaluated on the validation dataset, and the best-performing model state is saved.","title":"method eval_and_save"},{"location":"muben.train/#method-evaluate","text":"evaluate( dataset, n_run: Optional[int] = 1, return_preds: Optional[bool] = False ) Evaluates the model's performance on the given dataset. Args: dataset (Dataset): The dataset to evaluate the model on. n_run (int, optional): Number of runs for evaluation. Defaults to 1. return_preds (bool, optional): Whether to return the predictions along with metrics. Defaults to False. Returns: dict, or (dict, numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray]) : Evaluation metrics, or tuple containing metrics and predictions based on return_preds .","title":"method evaluate"},{"location":"muben.train/#method-freeze","text":"freeze() Freezes all model parameters, preventing them from being updated during training. Returns: Trainer : The current instance with model parameters frozen.","title":"method freeze"},{"location":"muben.train/#method-freeze_backbone","text":"freeze_backbone() Freezes the backbone parameters of the model, preventing them from being updated during training. Returns: Trainer : The current instance with backbone parameters frozen.","title":"method freeze_backbone"},{"location":"muben.train/#method-get_dataloader","text":"get_dataloader( dataset, shuffle: Optional[bool] = False, batch_size: Optional[int] = 0 ) Creates a DataLoader for the specified dataset. Args: dataset : Dataset for which the DataLoader is to be created. shuffle (bool, optional): Whether to shuffle the data. Defaults to False. batch_size (int, optional): Batch size for the DataLoader. Uses the batch size from the configuration if not specified. Returns: DataLoader : The created DataLoader for the provided dataset.","title":"method get_dataloader"},{"location":"muben.train/#method-get_loss","text":"get_loss(logits, batch, n_steps_per_epoch=None) \u2192 Tensor Computes the loss for a batch of data. This method can be overridden by subclasses to implement custom loss computation logic. Args: logits (torch.Tensor): The predictions or logits produced by the model for the given batch. batch (Batch): The batch of training data. n_steps_per_epoch (int, optional): Represents the number of batches in a training epoch, used specifically for certain uncertainty methods like Bayesian Backpropagation (BBP). Returns: torch.Tensor : The computed loss for the batch.","title":"method get_loss"},{"location":"muben.train/#method-get_metrics","text":"get_metrics(lbs, preds, masks) Calculates evaluation metrics based on the given labels, predictions, and masks. This method computes the appropriate metrics based on the task type (classification or regression). Args: lbs (numpy.ndarray): Ground truth labels. preds (numpy.ndarray): Model predictions. masks (numpy.ndarray): Masks indicating valid entries in labels and predictions. Returns: dict : Computed metrics for evaluation.","title":"method get_metrics"},{"location":"muben.train/#method-inference","text":"inference(dataset, **kwargs) Conducts inference over an entire dataset using the model. Args: dataset (Dataset): The dataset for which inference needs to be performed. **kwargs : Additional keyword arguments. Returns: numpy.ndarray : The model outputs as logits or a tuple of logits.","title":"method inference"},{"location":"muben.train/#method-initialize","text":"initialize(*args, **kwargs) Initializes the trainer's status and its key components including the model, optimizer, learning rate scheduler, and loss function. This method sets up the training environment by initializing the model, optimizer, learning rate scheduler, and the loss function based on the provided configuration. It also prepares the trainer for logging and checkpointing mechanisms. Args: *args : Variable length argument list for model initialization. **kwargs : Arbitrary keyword arguments for model initialization. Returns: Trainer : The initialized Trainer instance ready for training.","title":"method initialize"},{"location":"muben.train/#method-initialize_loss","text":"initialize_loss(disable_focal_loss=False) Initializes the loss function based on the task type and specified uncertainty method. This method sets up the appropriate loss function for the training process, considering the task type (classification or regression) and whether any specific uncertainty methods (e.g., evidential or focal loss) are applied. Args: disable_focal_loss (bool, optional): If True, disables the use of focal loss, even if specified by the uncertainty method. Defaults to False. Returns: Trainer : The Trainer instance with the initialized loss function.","title":"method initialize_loss"},{"location":"muben.train/#method-initialize_model","text":"initialize_model(*args, **kwargs) Abstract method to initialize the model. This method should be implemented in subclasses of Trainer, providing the specific logic to initialize the model that will be used for training. Returns: Trainer : The Trainer instance with the model initialized.","title":"method initialize_model"},{"location":"muben.train/#method-initialize_optimizer","text":"initialize_optimizer(*args, **kwargs) Initializes the model's optimizer based on the set configurations. This method sets up the optimizer for the model's parameters. It includes special handling for SGLD-based uncertainty methods by differentiating between backbone and output layer parameters. Args: *args : Variable length argument list for optimizer initialization. **kwargs : Arbitrary keyword arguments for optimizer initialization. Returns: Trainer : The Trainer instance with the initialized optimizer.","title":"method initialize_optimizer"},{"location":"muben.train/#method-initialize_scheduler","text":"initialize_scheduler() Initializes the learning rate scheduler based on the training configuration. This method sets up the learning rate scheduler using the total number of training steps and the specified warmup ratio. Returns: Trainer : The Trainer instance with the initialized scheduler.","title":"method initialize_scheduler"},{"location":"muben.train/#method-inverse_standardize_preds","text":"inverse_standardize_preds( preds: Union[ndarray, Tuple[ndarray, ndarray]] ) \u2192 Union[ndarray, Tuple[ndarray, ndarray]] Transforms predictions back to their original scale if they have been standardized. Args: preds (numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray]): Model predictions, can either be a single array or a tuple containing two arrays for mean and variance, respectively. Returns: numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray] : Inverse-standardized predictions.","title":"method inverse_standardize_preds"},{"location":"muben.train/#method-load_checkpoint","text":"load_checkpoint() Loads the model from a checkpoint. This method attempts to load the model checkpoint from the configured path. It supports loading with and without considering the uncertainty estimation method used during training. Returns: bool : True if the model is successfully loaded from a checkpoint, otherwise False.","title":"method load_checkpoint"},{"location":"muben.train/#method-log_results","text":"log_results( metrics: dict, logging_func=<bound method Logger.info of <Logger trainer.trainer (WARNING)>> ) Logs evaluation metrics using the specified logging function. Args: metrics (dict): Dictionary containing evaluation metrics to be logged. logging_func (function, optional): Logging function to which metrics will be sent. Defaults to logger.info . Returns: None","title":"method log_results"},{"location":"muben.train/#method-process_logits","text":"process_logits(logits: ndarray) \u2192 Union[ndarray, Tuple[ndarray, ndarray]] Processes the output logits based on the training tasks or variants. Args: logits (numpy.ndarray): The raw logits produced by the model. Returns: numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray] : Processed logits or a tuple containing processed logits based on the task type.","title":"method process_logits"},{"location":"muben.train/#method-run","text":"run() Executes the training and evaluation process. This method serves as the main entry point for the training process, orchestrating the execution based on the specified uncertainty method. It handles different training strategies like ensembles, SWAG, temperature scaling, and more. Returns: None","title":"method run"},{"location":"muben.train/#method-run_ensembles","text":"run_ensembles() Trains and evaluates an ensemble of models. This method is used for uncertainty estimation through model ensembles, training multiple models with different seeds and evaluating their collective performance. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method run_ensembles"},{"location":"muben.train/#method-run_focal_loss","text":"run_focal_loss() Runs the training and evaluation pipeline utilizing focal loss. Focal loss is used to address class imbalance by focusing more on hard-to-classify examples. Temperature scaling can optionally be applied after training with focal loss. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method run_focal_loss"},{"location":"muben.train/#method-run_iso_calibration","text":"run_iso_calibration() Performs isotonic calibration. Isotonic calibration is applied to calibrate the uncertainties of the model's predictions, based on the approach described in 'Accurate Uncertainties for Deep Learning Using Calibrated Regression'. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method run_iso_calibration"},{"location":"muben.train/#method-run_sgld","text":"run_sgld() Executes training and evaluation with Stochastic Gradient Langevin Dynamics (SGLD). SGLD is used for uncertainty estimation, incorporating random noise into the gradients to explore the model's parameter space more broadly. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method run_sgld"},{"location":"muben.train/#method-run_single_shot","text":"run_single_shot(apply_test=True) Runs the training and evaluation pipeline for a single iteration. This method handles the process of training the model and optionally evaluating it on a test dataset. It is designed for a straightforward, single iteration of training and testing. Args: apply_test (bool, optional): Whether to run the test function as part of the process. Defaults to True. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method run_single_shot"},{"location":"muben.train/#method-run_swag","text":"run_swag() Executes the training and evaluation pipeline using the SWAG method. Stochastic Weight Averaging Gaussian (SWAG) is used for uncertainty estimation. This method involves training the model with early stopping and applying SWAG for post-training uncertainty estimation. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method run_swag"},{"location":"muben.train/#method-run_temperature_scaling","text":"run_temperature_scaling() Executes the training and evaluation pipeline with temperature scaling. Temperature scaling is applied as a post-processing step to calibrate the confidence of the model's predictions. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method run_temperature_scaling"},{"location":"muben.train/#method-save_checkpoint","text":"save_checkpoint() Saves the current model state as a checkpoint. This method checks the disable_result_saving configuration flag before saving. If saving is disabled, it logs a warning and does not perform the save operation. Returns: Trainer : The current instance after attempting to save the model checkpoint.","title":"method save_checkpoint"},{"location":"muben.train/#method-save_results","text":"save_results(path, preds, variances, lbs, masks) Saves the model predictions, variances, ground truth labels, and masks to disk. This method saves the results of model predictions to a specified path. It is capable of handling both the predictions and their associated variances, along with the ground truth labels and masks that indicate which data points should be considered in the analysis. If the configuration flag disable_result_saving is set to True, the method will log a warning and not perform any saving operation. Args: path (str): The destination path where the results will be saved. preds (array_like): The predictions generated by the model. variances (array_like): The variances associated with each prediction, indicating the uncertainty of the predictions. lbs (array_like): The ground truth labels against which the model's predictions can be evaluated. masks (array_like): Masks indicating which data points are valid and should be considered in the evaluation. Returns: None : This method does not return any value.","title":"method save_results"},{"location":"muben.train/#method-set_mode","text":"set_mode(mode: str) Sets the training mode for the model. Depending on the mode, the model is set to training, evaluation, or testing. This method is essential for correctly configuring the model's state for different phases of the training and evaluation process. Args: mode (str): The mode to set the model to. Should be one of 'train', 'eval', or 'test'. Returns: Trainer : The Trainer instance with the model set to the specified mode.","title":"method set_mode"},{"location":"muben.train/#method-standardize_training_lbs","text":"standardize_training_lbs() Standardizes the label distribution of the training dataset for regression tasks. This method applies standardization to the labels of the training dataset, transforming them to a standard Gaussian distribution. It's applicable only for regression tasks. Returns: Trainer : The Trainer instance with standardized training labels.","title":"method standardize_training_lbs"},{"location":"muben.train/#method-swa_session","text":"swa_session() Executes the SWA session. This method is intended to be overridden by child classes for specialized handling of optimizer or model initialization required by SWA (Stochastic Weight Averaging). Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method swa_session"},{"location":"muben.train/#method-test","text":"test(load_best_model=True, return_preds=False) Tests the model's performance on the test dataset. Args: load_best_model (bool, optional): Whether to load the best model saved during training for testing. Defaults to True. return_preds (bool, optional): Whether to return the predictions along with metrics. Defaults to False. Returns: dict, or tuple[dict, numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray]] : Evaluation metrics (and predictions) for the test dataset.","title":"method test"},{"location":"muben.train/#method-test_on_training_data","text":"test_on_training_data( load_best_model=True, return_preds=False, disable_result_saving=False ) Tests the model's performance on the training dataset. This method is useful for understanding the model's performance on the data it was trained on, which can provide insights into overfitting or underfitting. Args: load_best_model (bool, optional): If True, loads the best model saved during training. Defaults to True. return_preds (bool, optional): If True, returns the predictions along with the evaluation metrics. Defaults to False. disable_result_saving (bool, optional): If True, disables saving the results to disk. Defaults to False. Returns: dict, or tuple[dict, numpy.ndarray or Tuple[numpy.ndarray, numpy.ndarray]] : Evaluation metrics, or a tuple containing metrics and predictions if return_preds is True.","title":"method test_on_training_data"},{"location":"muben.train/#method-train","text":"train(use_valid_dataset=False) Executes the training process for the model. Optionally allows for training using the validation dataset instead of the training dataset. This option can be useful for certain model calibration techniques like temperature scaling. Args: use_valid_dataset (bool, optional): Determines if the validation dataset should be used for training instead of the training dataset. Defaults to False. Returns: None : This method returns None.","title":"method train"},{"location":"muben.train/#method-training_epoch","text":"training_epoch(data_loader) Performs a single epoch of training using the provided data loader. This method iterates over the data loader, performs the forward pass, computes the loss, and updates the model parameters. Args: data_loader (DataLoader): DataLoader object providing batches of training data. Returns: float : The average training loss for the epoch.","title":"method training_epoch"},{"location":"muben.train/#method-ts_session","text":"ts_session() Executes the temperature scaling session. This session involves retraining the model on the validation set with a modified learning rate and epochs to apply temperature scaling for model calibration. Returns: Trainer : Self reference to the Trainer object, allowing for method chaining.","title":"method ts_session"},{"location":"muben.train/#method-unfreeze","text":"unfreeze() Unfreezes all model parameters, allowing them to be updated during training. Returns: Trainer : The current instance with model parameters unfrozen.","title":"method unfreeze"},{"location":"muben.train/#method-unfreeze_backbone","text":"unfreeze_backbone() Unfreezes the backbone parameters of the model, allowing them to be updated during training. Returns: Trainer : The current instance with backbone parameters unfrozen.","title":"method unfreeze_backbone"},{"location":"muben.utils/","text":"module muben.utils Utility functions to support argument parsing, data loading, model training and evalution. module argparser Argument Parser. Note The ArgumentParser class is modified from huggingface/transformers implementation. class ArgumentParser This subclass of argparse.ArgumentParser uses type hints on dataclasses to generate arguments. The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed) arguments to the parser after initialization and you'll get the output back after parsing as an additional namespace. Optional: To create sub argument groups use the _argument_group_name attribute in the dataclass. method __init__ __init__( dataclass_types: Union[DataClassType, Iterable[DataClassType]], **kwargs ) Args: dataclass_types: Dataclass type, or list of dataclass types for which we will \"fill\" instances with the parsed args. kwargs: (Optional) Passed to argparse.ArgumentParser() in the regular way. method parse_args_into_dataclasses parse_args_into_dataclasses( args=None, return_remaining_strings=False, look_for_args_file=True, args_filename=None, args_file_flag=None ) \u2192 Tuple[DataClass, ] Parse command-line args into instances of the specified dataclass types. This relies on argparse's ArgumentParser.parse_known_args . See the doc at: docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args Args: args: List of strings to parse. The default is taken from sys.argv. (same as argparse.ArgumentParser) return_remaining_strings: If true, also return a list of remaining argument strings. look_for_args_file: If true, will look for a \".args\" file with the same base name as the entry point script for this process, and will append its potential content to the command line args. args_filename: If not None, will uses this file instead of the \".args\" file specified in the previous argument. args_file_flag: If not None, will look for a file in the command-line args specified with this flag. The flag can be specified multiple times and precedence is determined by the order (last one wins). Returns: Tuple consisting of: the dataclass instances in the same order as they were passed to the initializer.abspath if applicable, an additional namespace for more (non-dataclass backed) arguments added to the parser after initialization. The potential list of remaining argument strings. (same as argparse.ArgumentParser.parse_known_args) method parse_dict parse_dict(args: Dict[str, Any]) \u2192 Tuple[DataClass, ] Alternative helper method that does not use argparse at all, instead uses a dict and populating the dataclass types. Args: args ( dict ): dict containing config values Returns: Tuple consisting of: the dataclass instances in the same order as they were passed to the initializer. method parse_json_file parse_json_file(json_file: str) \u2192 Tuple[DataClass, ] Alternative helper method that does not use argparse at all, instead loading a json file and populating the dataclass types. Args: json_file ( str or os.PathLike ): File name of the json file to parse Returns: Tuple consisting of: the dataclass instances in the same order as they were passed to the initializer. method parse_yaml_file parse_yaml_file(yaml_file: str) \u2192 Tuple[DataClass, ] Alternative helper method that does not use argparse at all, instead loading a yaml file and populating the dataclass types. Args: yaml_file ( str or os.PathLike ): File name of the yaml file to parse Returns: Tuple consisting of: the dataclass instances in the same order as they were passed to the initializer. module chem Molecular descriptors and features function smiles_to_2d_coords smiles_to_2d_coords(smiles) Converts SMILES strings to 2D coordinates. Args: smiles (str): A SMILES string representing the molecule. Returns: numpy.ndarray : A 2D array of coordinates for the molecule. function smiles_to_3d_coords smiles_to_3d_coords(smiles, n_conformer) Converts SMILES strings to 3D coordinates. Args: smiles (str): A SMILES string representing the molecule. n_conformer (int): Number of conformers to generate for the molecule. Returns: list[numpy.ndarray] : A list of 3D arrays of coordinates for each conformer of the molecule. function smiles_to_coords smiles_to_coords(smiles, n_conformer=10) Converts SMILES strings to 3D coordinates. Args: smiles (str): A SMILES string representing the molecule. n_conformer (int): Number of conformers to generate for the molecule. Returns: list[numpy.ndarray] : A list of 3D arrays of coordinates for each conformer of the molecule. function rdkit_2d_features_normalized_generator rdkit_2d_features_normalized_generator(mol) \u2192 ndarray Generates RDKit 2D normalized features for a molecule. Args: mol (str or Chem.Mol): A molecule represented as a SMILES string or an RDKit molecule object. Returns: numpy.ndarray : An array containing the RDKit 2D normalized features. function morgan_binary_features_generator morgan_binary_features_generator( mol, radius: int = 2, num_bits: int = 1024 ) \u2192 ndarray Generates a binary Morgan fingerprint for a molecule. Args: mol (str or Chem.Mol): A molecule represented as a SMILES string or an RDKit molecule object. radius (int): Radius of the Morgan fingerprint. num_bits (int): Number of bits in the Morgan fingerprint. Returns: numpy.ndarray : An array containing the binary Morgan fingerprint. function smiles_to_atom_ids smiles_to_atom_ids(smiles: str) \u2192 list[int] Converts SMILES strings to a list of atom IDs with hydrogens included. Args: smiles (str): A SMILES string representing the molecule. Returns: list[int] : A list of atomic numbers corresponding to the atoms in the molecule. function atom_to_atom_ids atom_to_atom_ids(atoms: list[str]) \u2192 list[int] Converts a list of atom symbols to a list of atom IDs. Args: atoms (list[str]): A list of atom symbols. Returns: list[int] : A list of atomic numbers corresponding to the provided atom symbols. function smiles_to_2d_graph smiles_to_2d_graph(smiles) Converts SMILES strings to 2D graph representations. Args: smiles (str): A SMILES string representing the molecule. Returns: tuple[list[int], list[list[int]]] : A tuple containing a list of atom IDs and a list of bonds represented as pairs of atom indices. module metrics These Python functions are designed to calculate various metrics for classification and regression tasks, particularly focusing on evaluating the performance of models on tasks involving predictions with associated uncertainties. function classification_metrics classification_metrics(preds, lbs, masks, exclude: list = None) Calculates various metrics for classification tasks. This function computes ROC-AUC, PRC-AUC, ECE, MCE, NLL, and Brier score for classification predictions. Args: preds (numpy.ndarray): Predicted probabilities for each class. lbs (numpy.ndarray): Ground truth labels. masks (numpy.ndarray): Masks indicating valid data points for evaluation. exclude (list, optional): List of metrics to exclude from the calculation. Returns: dict : A dictionary containing calculated metrics. function regression_metrics regression_metrics(preds, variances, lbs, masks, exclude: list = None) Calculates various metrics for regression tasks. Computes RMSE, MAE, NLL, and calibration error for regression predictions and their associated uncertainties. Args: preds (numpy.ndarray): Predicted values (means). variances (numpy.ndarray): Predicted variances. lbs (numpy.ndarray): Ground truth values. masks (numpy.ndarray): Masks indicating valid data points for evaluation. exclude (list, optional): List of metrics to exclude from the calculation. Returns: dict : A dictionary containing calculated metrics. function regression_calibration_error regression_calibration_error(lbs, preds, variances, n_bins=20) Calculates the calibration error for regression tasks. Uses the predicted means and variances to estimate the calibration error across a specified number of bins. Args: lbs (numpy.ndarray): Ground truth values. preds (numpy.ndarray): Predicted values (means). variances (numpy.ndarray): Predicted variances. n_bins (int, optional): Number of bins to use for calculating calibration error. Defaults to 20. Returns: float : The calculated calibration error. module io function set_log_path set_log_path(args, time) Sets up the log path based on given arguments and time. Args: args : Command-line arguments or any object with attributes dataset_name , model_name , feature_type , and uncertainty_method . time (str): A string representing the current time or a unique identifier for the log file. Returns: str : The constructed log path. function set_logging set_logging(log_path: Optional[str] = None) Sets up logging format and file handler. Args: log_path (Optional[str]): Path where to save the logging file. If None, no log file is saved. function logging_args logging_args(args) Logs model arguments. Args: args : The arguments to be logged. Can be an argparse Namespace or similar object. function remove_dir remove_dir(directory: str) Removes a directory and its subtree. Args: directory (str): The directory to remove. function init_dir init_dir(directory: str, clear_original_content: Optional[bool] = True) Initializes a directory. Clears content if specified and directory exists. Args: directory (str): The directory to initialize. clear_original_content (Optional[bool]): Whether to clear the original content of the directory if it exists. function save_json save_json(obj, path: str, collapse_level: Optional[int] = None) Saves an object to a JSON file. Args: obj : The object to save. path (str): The path to the file where the object will be saved. collapse_level (Optional[int]): Specifies how to prettify the JSON output. If set, collapses levels greater than this. function prettify_json prettify_json(text, indent=2, collapse_level=4) Prettifies JSON text by collapsing indent levels higher than collapse_level . Args: text (str): Input JSON text. indent (int): The indentation value of the JSON text. collapse_level (int): The level from which to stop adding new lines. Returns: str : The prettified JSON text. function convert_arguments_from_argparse convert_arguments_from_argparse(args) Converts argparse Namespace to transformers-style arguments. Args: args : argparse Namespace object. Returns: str : Transformers style arguments string. function save_results save_results(path, preds, variances, lbs, masks) Saves prediction results to a file. Args: path (str): Path where to save the results. preds : Predictions to save. variances : Variances associated with predictions. lbs : Ground truth labels. masks : Masks indicating valid entries. function load_results load_results(result_paths: list[str]) Loads prediction results from files. Args: result_paths (list[str]): Paths to the result files. Returns: tuple : Predictions, variances, labels, and masks loaded from the files. function load_lmdb load_lmdb(data_path, keys_to_load: list[str] = None, return_dict: bool = False) Loads data from an LMDB file. Args: data_path (str): Path to the LMDB file. keys_to_load (list[str], optional): Specific keys to load from the LMDB file. Loads all keys if None. return_dict (bool): Whether to return a dictionary of loaded values. Returns: dict or tuple : Loaded values from the LMDB file. The format depends on return_dict . function load_unimol_preprocessed load_unimol_preprocessed(data_dir: str) Loads preprocessed UniMol dataset splits from an LMDB file. Args: data_dir (str): Directory containing the LMDB dataset splits. Returns: dict : Loaded dataset splits (train, valid, test).","title":"muben.utils"},{"location":"muben.utils/#module-mubenutils","text":"Utility functions to support argument parsing, data loading, model training and evalution.","title":"module muben.utils"},{"location":"muben.utils/#module-argparser","text":"Argument Parser. Note The ArgumentParser class is modified from huggingface/transformers implementation.","title":"module argparser"},{"location":"muben.utils/#class-argumentparser","text":"This subclass of argparse.ArgumentParser uses type hints on dataclasses to generate arguments. The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed) arguments to the parser after initialization and you'll get the output back after parsing as an additional namespace. Optional: To create sub argument groups use the _argument_group_name attribute in the dataclass.","title":"class ArgumentParser"},{"location":"muben.utils/#method-__init__","text":"__init__( dataclass_types: Union[DataClassType, Iterable[DataClassType]], **kwargs ) Args: dataclass_types: Dataclass type, or list of dataclass types for which we will \"fill\" instances with the parsed args. kwargs: (Optional) Passed to argparse.ArgumentParser() in the regular way.","title":"method __init__"},{"location":"muben.utils/#method-parse_args_into_dataclasses","text":"parse_args_into_dataclasses( args=None, return_remaining_strings=False, look_for_args_file=True, args_filename=None, args_file_flag=None ) \u2192 Tuple[DataClass, ] Parse command-line args into instances of the specified dataclass types. This relies on argparse's ArgumentParser.parse_known_args . See the doc at: docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args Args: args: List of strings to parse. The default is taken from sys.argv. (same as argparse.ArgumentParser) return_remaining_strings: If true, also return a list of remaining argument strings. look_for_args_file: If true, will look for a \".args\" file with the same base name as the entry point script for this process, and will append its potential content to the command line args. args_filename: If not None, will uses this file instead of the \".args\" file specified in the previous argument. args_file_flag: If not None, will look for a file in the command-line args specified with this flag. The flag can be specified multiple times and precedence is determined by the order (last one wins). Returns: Tuple consisting of: the dataclass instances in the same order as they were passed to the initializer.abspath if applicable, an additional namespace for more (non-dataclass backed) arguments added to the parser after initialization. The potential list of remaining argument strings. (same as argparse.ArgumentParser.parse_known_args)","title":"method parse_args_into_dataclasses"},{"location":"muben.utils/#method-parse_dict","text":"parse_dict(args: Dict[str, Any]) \u2192 Tuple[DataClass, ] Alternative helper method that does not use argparse at all, instead uses a dict and populating the dataclass types. Args: args ( dict ): dict containing config values Returns: Tuple consisting of: the dataclass instances in the same order as they were passed to the initializer.","title":"method parse_dict"},{"location":"muben.utils/#method-parse_json_file","text":"parse_json_file(json_file: str) \u2192 Tuple[DataClass, ] Alternative helper method that does not use argparse at all, instead loading a json file and populating the dataclass types. Args: json_file ( str or os.PathLike ): File name of the json file to parse Returns: Tuple consisting of: the dataclass instances in the same order as they were passed to the initializer.","title":"method parse_json_file"},{"location":"muben.utils/#method-parse_yaml_file","text":"parse_yaml_file(yaml_file: str) \u2192 Tuple[DataClass, ] Alternative helper method that does not use argparse at all, instead loading a yaml file and populating the dataclass types. Args: yaml_file ( str or os.PathLike ): File name of the yaml file to parse Returns: Tuple consisting of: the dataclass instances in the same order as they were passed to the initializer.","title":"method parse_yaml_file"},{"location":"muben.utils/#module-chem","text":"Molecular descriptors and features","title":"module chem"},{"location":"muben.utils/#function-smiles_to_2d_coords","text":"smiles_to_2d_coords(smiles) Converts SMILES strings to 2D coordinates. Args: smiles (str): A SMILES string representing the molecule. Returns: numpy.ndarray : A 2D array of coordinates for the molecule.","title":"function smiles_to_2d_coords"},{"location":"muben.utils/#function-smiles_to_3d_coords","text":"smiles_to_3d_coords(smiles, n_conformer) Converts SMILES strings to 3D coordinates. Args: smiles (str): A SMILES string representing the molecule. n_conformer (int): Number of conformers to generate for the molecule. Returns: list[numpy.ndarray] : A list of 3D arrays of coordinates for each conformer of the molecule.","title":"function smiles_to_3d_coords"},{"location":"muben.utils/#function-smiles_to_coords","text":"smiles_to_coords(smiles, n_conformer=10) Converts SMILES strings to 3D coordinates. Args: smiles (str): A SMILES string representing the molecule. n_conformer (int): Number of conformers to generate for the molecule. Returns: list[numpy.ndarray] : A list of 3D arrays of coordinates for each conformer of the molecule.","title":"function smiles_to_coords"},{"location":"muben.utils/#function-rdkit_2d_features_normalized_generator","text":"rdkit_2d_features_normalized_generator(mol) \u2192 ndarray Generates RDKit 2D normalized features for a molecule. Args: mol (str or Chem.Mol): A molecule represented as a SMILES string or an RDKit molecule object. Returns: numpy.ndarray : An array containing the RDKit 2D normalized features.","title":"function rdkit_2d_features_normalized_generator"},{"location":"muben.utils/#function-morgan_binary_features_generator","text":"morgan_binary_features_generator( mol, radius: int = 2, num_bits: int = 1024 ) \u2192 ndarray Generates a binary Morgan fingerprint for a molecule. Args: mol (str or Chem.Mol): A molecule represented as a SMILES string or an RDKit molecule object. radius (int): Radius of the Morgan fingerprint. num_bits (int): Number of bits in the Morgan fingerprint. Returns: numpy.ndarray : An array containing the binary Morgan fingerprint.","title":"function morgan_binary_features_generator"},{"location":"muben.utils/#function-smiles_to_atom_ids","text":"smiles_to_atom_ids(smiles: str) \u2192 list[int] Converts SMILES strings to a list of atom IDs with hydrogens included. Args: smiles (str): A SMILES string representing the molecule. Returns: list[int] : A list of atomic numbers corresponding to the atoms in the molecule.","title":"function smiles_to_atom_ids"},{"location":"muben.utils/#function-atom_to_atom_ids","text":"atom_to_atom_ids(atoms: list[str]) \u2192 list[int] Converts a list of atom symbols to a list of atom IDs. Args: atoms (list[str]): A list of atom symbols. Returns: list[int] : A list of atomic numbers corresponding to the provided atom symbols.","title":"function atom_to_atom_ids"},{"location":"muben.utils/#function-smiles_to_2d_graph","text":"smiles_to_2d_graph(smiles) Converts SMILES strings to 2D graph representations. Args: smiles (str): A SMILES string representing the molecule. Returns: tuple[list[int], list[list[int]]] : A tuple containing a list of atom IDs and a list of bonds represented as pairs of atom indices.","title":"function smiles_to_2d_graph"},{"location":"muben.utils/#module-metrics","text":"These Python functions are designed to calculate various metrics for classification and regression tasks, particularly focusing on evaluating the performance of models on tasks involving predictions with associated uncertainties.","title":"module metrics"},{"location":"muben.utils/#function-classification_metrics","text":"classification_metrics(preds, lbs, masks, exclude: list = None) Calculates various metrics for classification tasks. This function computes ROC-AUC, PRC-AUC, ECE, MCE, NLL, and Brier score for classification predictions. Args: preds (numpy.ndarray): Predicted probabilities for each class. lbs (numpy.ndarray): Ground truth labels. masks (numpy.ndarray): Masks indicating valid data points for evaluation. exclude (list, optional): List of metrics to exclude from the calculation. Returns: dict : A dictionary containing calculated metrics.","title":"function classification_metrics"},{"location":"muben.utils/#function-regression_metrics","text":"regression_metrics(preds, variances, lbs, masks, exclude: list = None) Calculates various metrics for regression tasks. Computes RMSE, MAE, NLL, and calibration error for regression predictions and their associated uncertainties. Args: preds (numpy.ndarray): Predicted values (means). variances (numpy.ndarray): Predicted variances. lbs (numpy.ndarray): Ground truth values. masks (numpy.ndarray): Masks indicating valid data points for evaluation. exclude (list, optional): List of metrics to exclude from the calculation. Returns: dict : A dictionary containing calculated metrics.","title":"function regression_metrics"},{"location":"muben.utils/#function-regression_calibration_error","text":"regression_calibration_error(lbs, preds, variances, n_bins=20) Calculates the calibration error for regression tasks. Uses the predicted means and variances to estimate the calibration error across a specified number of bins. Args: lbs (numpy.ndarray): Ground truth values. preds (numpy.ndarray): Predicted values (means). variances (numpy.ndarray): Predicted variances. n_bins (int, optional): Number of bins to use for calculating calibration error. Defaults to 20. Returns: float : The calculated calibration error.","title":"function regression_calibration_error"},{"location":"muben.utils/#module-io","text":"","title":"module io"},{"location":"muben.utils/#function-set_log_path","text":"set_log_path(args, time) Sets up the log path based on given arguments and time. Args: args : Command-line arguments or any object with attributes dataset_name , model_name , feature_type , and uncertainty_method . time (str): A string representing the current time or a unique identifier for the log file. Returns: str : The constructed log path.","title":"function set_log_path"},{"location":"muben.utils/#function-set_logging","text":"set_logging(log_path: Optional[str] = None) Sets up logging format and file handler. Args: log_path (Optional[str]): Path where to save the logging file. If None, no log file is saved.","title":"function set_logging"},{"location":"muben.utils/#function-logging_args","text":"logging_args(args) Logs model arguments. Args: args : The arguments to be logged. Can be an argparse Namespace or similar object.","title":"function logging_args"},{"location":"muben.utils/#function-remove_dir","text":"remove_dir(directory: str) Removes a directory and its subtree. Args: directory (str): The directory to remove.","title":"function remove_dir"},{"location":"muben.utils/#function-init_dir","text":"init_dir(directory: str, clear_original_content: Optional[bool] = True) Initializes a directory. Clears content if specified and directory exists. Args: directory (str): The directory to initialize. clear_original_content (Optional[bool]): Whether to clear the original content of the directory if it exists.","title":"function init_dir"},{"location":"muben.utils/#function-save_json","text":"save_json(obj, path: str, collapse_level: Optional[int] = None) Saves an object to a JSON file. Args: obj : The object to save. path (str): The path to the file where the object will be saved. collapse_level (Optional[int]): Specifies how to prettify the JSON output. If set, collapses levels greater than this.","title":"function save_json"},{"location":"muben.utils/#function-prettify_json","text":"prettify_json(text, indent=2, collapse_level=4) Prettifies JSON text by collapsing indent levels higher than collapse_level . Args: text (str): Input JSON text. indent (int): The indentation value of the JSON text. collapse_level (int): The level from which to stop adding new lines. Returns: str : The prettified JSON text.","title":"function prettify_json"},{"location":"muben.utils/#function-convert_arguments_from_argparse","text":"convert_arguments_from_argparse(args) Converts argparse Namespace to transformers-style arguments. Args: args : argparse Namespace object. Returns: str : Transformers style arguments string.","title":"function convert_arguments_from_argparse"},{"location":"muben.utils/#function-save_results","text":"save_results(path, preds, variances, lbs, masks) Saves prediction results to a file. Args: path (str): Path where to save the results. preds : Predictions to save. variances : Variances associated with predictions. lbs : Ground truth labels. masks : Masks indicating valid entries.","title":"function save_results"},{"location":"muben.utils/#function-load_results","text":"load_results(result_paths: list[str]) Loads prediction results from files. Args: result_paths (list[str]): Paths to the result files. Returns: tuple : Predictions, variances, labels, and masks loaded from the files.","title":"function load_results"},{"location":"muben.utils/#function-load_lmdb","text":"load_lmdb(data_path, keys_to_load: list[str] = None, return_dict: bool = False) Loads data from an LMDB file. Args: data_path (str): Path to the LMDB file. keys_to_load (list[str], optional): Specific keys to load from the LMDB file. Loads all keys if None. return_dict (bool): Whether to return a dictionary of loaded values. Returns: dict or tuple : Loaded values from the LMDB file. The format depends on return_dict .","title":"function load_lmdb"},{"location":"muben.utils/#function-load_unimol_preprocessed","text":"load_unimol_preprocessed(data_dir: str) Loads preprocessed UniMol dataset splits from an LMDB file. Args: data_dir (str): Directory containing the LMDB dataset splits. Returns: dict : Loaded dataset splits (train, valid, test).","title":"function load_unimol_preprocessed"},{"location":"overview/","text":"Project Overview The muben package consists of several sub-packages, each tailored for specific functionalities within the backbond and/or UQ method trainig workflow. Below is a detailed overview of each sub-package and its purpose: module muben.args Manages command-line arguments and configuration settings for the muben package. Command-line argument/configuration file parsing Parameter validation and defaults module muben.dataset Provides functionality for loading, processing, and handling datasets. Dataset loading Feature generation Data preparation for dataloader Batching functions Collating functions module muben.layers Defines the output layer for compatibility with various objects (classification/regression), number of tasks, and UQ method (especially for Bayes-by-Backprop). Custom the output layer module muben.model Focuses on model definition and implementation. Model architecture and forward functions Loading functions for pre-trained model weights module muben.uncertainty Specializes in uncertainty estimation model architecture and training schemes. Notice that some UQ methods without special training steps or the need for modifying backbone layers are directly incorporated in the trainer. Uncertainty estimation functions Uncertainty estimation training schemes module muben.train Dedicated to the training process, including batch processing, epoch management, and callback functionalities. This module ensures efficient and effective model training, providing a robust framework for different training regimes. Training loops and batch processing Callbacks and training hooks Training metrics and evaluation module muben.utils Offers a collection of utility functions and helper tools that support the broader functionality of the muben package. This module includes miscellaneous functionalities such as logging, data manipulation, and performance metrics. Logging and debugging tools Data manipulation utilities Performance and evaluation metrics","title":"Overview"},{"location":"overview/#project-overview","text":"The muben package consists of several sub-packages, each tailored for specific functionalities within the backbond and/or UQ method trainig workflow. Below is a detailed overview of each sub-package and its purpose:","title":"Project Overview"},{"location":"overview/#module-mubenargs","text":"Manages command-line arguments and configuration settings for the muben package. Command-line argument/configuration file parsing Parameter validation and defaults","title":"module muben.args"},{"location":"overview/#module-mubendataset","text":"Provides functionality for loading, processing, and handling datasets. Dataset loading Feature generation Data preparation for dataloader Batching functions Collating functions","title":"module muben.dataset"},{"location":"overview/#module-mubenlayers","text":"Defines the output layer for compatibility with various objects (classification/regression), number of tasks, and UQ method (especially for Bayes-by-Backprop). Custom the output layer","title":"module muben.layers"},{"location":"overview/#module-mubenmodel","text":"Focuses on model definition and implementation. Model architecture and forward functions Loading functions for pre-trained model weights","title":"module muben.model"},{"location":"overview/#module-mubenuncertainty","text":"Specializes in uncertainty estimation model architecture and training schemes. Notice that some UQ methods without special training steps or the need for modifying backbone layers are directly incorporated in the trainer. Uncertainty estimation functions Uncertainty estimation training schemes","title":"module muben.uncertainty"},{"location":"overview/#module-mubentrain","text":"Dedicated to the training process, including batch processing, epoch management, and callback functionalities. This module ensures efficient and effective model training, providing a robust framework for different training regimes. Training loops and batch processing Callbacks and training hooks Training metrics and evaluation","title":"module muben.train"},{"location":"overview/#module-mubenutils","text":"Offers a collection of utility functions and helper tools that support the broader functionality of the muben package. This module includes miscellaneous functionalities such as logging, data manipulation, and performance metrics. Logging and debugging tools Data manipulation utilities Performance and evaluation metrics","title":"module muben.utils"},{"location":"train.cli/","text":"Running Experiments on CLI Info Please ensure you have clone the repo and navigated to the MUBen/ directory in your local environment to begin working with the project. The most straightforward approach to replicate our experimental results is using the python scripts provided in the MUBen repo with the following pipeline. Fine-Tuning the Models The ./run/ directory contains the entry scripts to fine-tuning each of the backbone-UQ combinations. Currently, the script ./run/run.py is adopted to run all backbone models except for GROVER and Uni-Mol, whose entry scripts are ./run/grover.py and ./run/unimol.py , respectively. Specify Arguments Using Command Lines An example of running the DNN model with RDKit features with the MC Dropout UQ method on the BBBP dataset is CUDA_VISIBLE_DEVICES=0 \\ PYTHONPATH=\".\" \\ python ./run/run.py \\ --descriptor_type \"RDKit\" \\ --data_folder \"./data/files\" \\ --dataset_name \"bbbp\" \\ --uncertainty_method \"MCDropout\" \\ --lr 0.0001 \\ --n_epochs 200 \\ --batch_size 256 \\ --seed 0 In the example, the --descriptor_type argument is used to select the backbone models used in our experiments. It has 4 options: {\"RDKit\", \"Linear\", \"2D\", \"3D\"}, which corresponds to the DNN, ChemBERTa, GIN and TorchMD-NET backbone models in the CLI, respectively. In the future versions, we may consider including multiple backbone models that correspond to one descriptor, which requires us to specify the --model_name argument to separate the backbones. But currently, we do not need to worry about that and can leave --model_name as default. Info For the interpretation of each argument, please check the muben.args API or directly refer to the code implementation . Notice that the API documentation may not be entirely comprehensive. Similarly, we can also run the ChemBERTa model with the SGLD UQ method on the ESOL dataset using CUDA_VISIBLE_DEVICES=0 \\ PYTHONPATH=\".\" \\ python ./run/run.py \\ --descriptor_type \"Linear\" \\ --data_folder \"./data/files\" \\ --dataset_name \"esol\" \\ --uncertainty_method \"SGLD\" \\ --lr 0.00005 \\ --n_epochs 100 \\ --batch_size 128 \\ --seed 0 \\ --regression_with_variance Warning For regression tasks, the argument --regression_with_variance is vital to guarantee a valid result with predicted variance. To run GROVER or Uni-Mol, we just need to replace run.py by the corresponding script, and slightly modify the arguments: CUDA_VISIBLE_DEVICES=0 \\ PYTHONPATH=\".\" \\ python ./run/unimol.py \\ --data_folder \"./data/files\" \\ --unimol_feature_folder \"./data/UniMol/\" \\ --dataset_name \"bbbp\" \\ --checkpoint_path \"./models/unimol_base.pt\" \\ --uncertainty_method \"MCDropout\" \\ ... Specify Arguments using .yaml Files Another way of specifying arguments is through the .yaml scripts, which provides more readable data structure than .json files. We have provided an example configuration script within the ./scripts/ directory, which runs GIN on the FreeSolv dataset with deterministic (\"none\") UQ method. To use it to specify arguments, we can run the python program with PYTHONPATH=\".\" CUDA_VISIBLE_DEVICES=0 python ./run/run.py ./scripts/config-example.yaml This approach could be helpful while debugging the code on VSCode. Logging and WandB By default, this project uses local logging files ( *.log ) and WandB to track training status. The log files are stored as ./logs/<dataset>/<model>/<uncertainty>/<running_time>.log . You can change the file path by specifying the --log_path argument, or disable log saving by setting --log_path=\"disabled\" . To use WandB, you first need to register an account and sign in on your machine with wandb login . If you are running your code on a public device, you can instead use program-wise signing in by specifying the --wandb_api_key argument while running our code. You can find your API key in your browser here: https://wandb.ai/authorize. To disable WandB, use --disable_wandb [true] . By default, we use MUBen-<dataset> as WandB project name and <model>-<uncertainty> as the model name. You can change this behavior by specifying the --wandb_project and --wandb_name arguments. Data Loading The progress will automatically create the necessary features (molecular descriptors) required by backbone models from the SMILES strings if they are loaded properly. The processed features are stored in the <bottom-level data folder>/processed/ directory as <train/valid/test>.pt files by default, and will be automatically loaded the next time you apply the same backbone model on the same dataset. You can change this behavior with --disable_dataset_saving for disabling dataset saving or --ignore_preprocessed_dataset for not loading from the saved (processed) dataset. Constructing Morgan fingerprint, RDKit features or 3D conformations for Uni-Mol may take a while. You can accelerate this process by utilizing multiple threads --num_preprocess_workers=n>1 (default is 8). For 3D conformations, we directly take advantage of the results from Uni-Mol but still keep the choice of generating them by ourselves if the Uni-Mol data files are not found. Calculating Metrics During training, we only calculate metrics necessary for early stopping and simple prediction performance evaluation. To get other metrics, you need to use the ./assist/results_get_metrics.py file. Specifically, you need to save the model predictions by not setting --disable_dataset_saving . The results are saved as ./<result_folder>/<dataset_name>/<model_name>/<uncertainty_method>/seed-<seed>/preds/<test_idx>.pt files. When the training is finished, you can run the ./assist/results_get_metrics.py file to generate all metrics for your model predictions. For example: PYTHONPATH=\".\" python ./assist/results_get_metrics.py [arguments] Make sure the arguments are updated to your needs.","title":"Running Experiments"},{"location":"train.cli/#running-experiments-on-cli","text":"Info Please ensure you have clone the repo and navigated to the MUBen/ directory in your local environment to begin working with the project. The most straightforward approach to replicate our experimental results is using the python scripts provided in the MUBen repo with the following pipeline.","title":"Running Experiments on CLI"},{"location":"train.cli/#fine-tuning-the-models","text":"The ./run/ directory contains the entry scripts to fine-tuning each of the backbone-UQ combinations. Currently, the script ./run/run.py is adopted to run all backbone models except for GROVER and Uni-Mol, whose entry scripts are ./run/grover.py and ./run/unimol.py , respectively.","title":"Fine-Tuning the Models"},{"location":"train.cli/#specify-arguments-using-command-lines","text":"An example of running the DNN model with RDKit features with the MC Dropout UQ method on the BBBP dataset is CUDA_VISIBLE_DEVICES=0 \\ PYTHONPATH=\".\" \\ python ./run/run.py \\ --descriptor_type \"RDKit\" \\ --data_folder \"./data/files\" \\ --dataset_name \"bbbp\" \\ --uncertainty_method \"MCDropout\" \\ --lr 0.0001 \\ --n_epochs 200 \\ --batch_size 256 \\ --seed 0 In the example, the --descriptor_type argument is used to select the backbone models used in our experiments. It has 4 options: {\"RDKit\", \"Linear\", \"2D\", \"3D\"}, which corresponds to the DNN, ChemBERTa, GIN and TorchMD-NET backbone models in the CLI, respectively. In the future versions, we may consider including multiple backbone models that correspond to one descriptor, which requires us to specify the --model_name argument to separate the backbones. But currently, we do not need to worry about that and can leave --model_name as default. Info For the interpretation of each argument, please check the muben.args API or directly refer to the code implementation . Notice that the API documentation may not be entirely comprehensive. Similarly, we can also run the ChemBERTa model with the SGLD UQ method on the ESOL dataset using CUDA_VISIBLE_DEVICES=0 \\ PYTHONPATH=\".\" \\ python ./run/run.py \\ --descriptor_type \"Linear\" \\ --data_folder \"./data/files\" \\ --dataset_name \"esol\" \\ --uncertainty_method \"SGLD\" \\ --lr 0.00005 \\ --n_epochs 100 \\ --batch_size 128 \\ --seed 0 \\ --regression_with_variance Warning For regression tasks, the argument --regression_with_variance is vital to guarantee a valid result with predicted variance. To run GROVER or Uni-Mol, we just need to replace run.py by the corresponding script, and slightly modify the arguments: CUDA_VISIBLE_DEVICES=0 \\ PYTHONPATH=\".\" \\ python ./run/unimol.py \\ --data_folder \"./data/files\" \\ --unimol_feature_folder \"./data/UniMol/\" \\ --dataset_name \"bbbp\" \\ --checkpoint_path \"./models/unimol_base.pt\" \\ --uncertainty_method \"MCDropout\" \\ ...","title":"Specify Arguments Using Command Lines"},{"location":"train.cli/#specify-arguments-using-yaml-files","text":"Another way of specifying arguments is through the .yaml scripts, which provides more readable data structure than .json files. We have provided an example configuration script within the ./scripts/ directory, which runs GIN on the FreeSolv dataset with deterministic (\"none\") UQ method. To use it to specify arguments, we can run the python program with PYTHONPATH=\".\" CUDA_VISIBLE_DEVICES=0 python ./run/run.py ./scripts/config-example.yaml This approach could be helpful while debugging the code on VSCode.","title":"Specify Arguments using .yaml Files"},{"location":"train.cli/#logging-and-wandb","text":"By default, this project uses local logging files ( *.log ) and WandB to track training status. The log files are stored as ./logs/<dataset>/<model>/<uncertainty>/<running_time>.log . You can change the file path by specifying the --log_path argument, or disable log saving by setting --log_path=\"disabled\" . To use WandB, you first need to register an account and sign in on your machine with wandb login . If you are running your code on a public device, you can instead use program-wise signing in by specifying the --wandb_api_key argument while running our code. You can find your API key in your browser here: https://wandb.ai/authorize. To disable WandB, use --disable_wandb [true] . By default, we use MUBen-<dataset> as WandB project name and <model>-<uncertainty> as the model name. You can change this behavior by specifying the --wandb_project and --wandb_name arguments.","title":"Logging and WandB"},{"location":"train.cli/#data-loading","text":"The progress will automatically create the necessary features (molecular descriptors) required by backbone models from the SMILES strings if they are loaded properly. The processed features are stored in the <bottom-level data folder>/processed/ directory as <train/valid/test>.pt files by default, and will be automatically loaded the next time you apply the same backbone model on the same dataset. You can change this behavior with --disable_dataset_saving for disabling dataset saving or --ignore_preprocessed_dataset for not loading from the saved (processed) dataset. Constructing Morgan fingerprint, RDKit features or 3D conformations for Uni-Mol may take a while. You can accelerate this process by utilizing multiple threads --num_preprocess_workers=n>1 (default is 8). For 3D conformations, we directly take advantage of the results from Uni-Mol but still keep the choice of generating them by ourselves if the Uni-Mol data files are not found.","title":"Data Loading"},{"location":"train.cli/#calculating-metrics","text":"During training, we only calculate metrics necessary for early stopping and simple prediction performance evaluation. To get other metrics, you need to use the ./assist/results_get_metrics.py file. Specifically, you need to save the model predictions by not setting --disable_dataset_saving . The results are saved as ./<result_folder>/<dataset_name>/<model_name>/<uncertainty_method>/seed-<seed>/preds/<test_idx>.pt files. When the training is finished, you can run the ./assist/results_get_metrics.py file to generate all metrics for your model predictions. For example: PYTHONPATH=\".\" python ./assist/results_get_metrics.py [arguments] Make sure the arguments are updated to your needs.","title":"Calculating Metrics"},{"location":"train.python/","text":"Using muben Package In this demonstration, we'll guide you through foundational training and testing of MUBen using the BBBP dataset as a minimal example. We've chosen the DNN as our backbone model because it is both efficient and offers satisfactory performance. For UQ, we'll evaluate both the Deterministic method (referred to as \"none\" within MUBen) and Temperature Scaling. While the procedures for other backbone models, UQ methods, or datasets are largely similar, you can explore specific variations by referring to API documentation. Info For a practical example of our setup, refer to the demo Jupyter Notebook provided on GitHub. Importing packages The first step is to import all the necessary packages from the MUBen source code that defines the datasets, backbone models, UQ methods, and trainers. import logging import wandb from transformers import set_seed from muben.utils.selectors import configure_selector, dataset_selector, model_selector from muben.train import Trainer from muben.utils.io import set_logging # initialize logger logger = logging.getLogger(__name__) Deterministic method -- training We first train the DNN model Deterministically. That is, we do not apply any UQ method to the model. Instead, we directly use its post-output-activation probabilities as its estimated reliability to its prediction. Here we pass necessary hyper-parameters to the configuration to control the training process. # Set up the logging format and random seed. # We do not use wandb for this demo, so we set its mode to \"disabled\". set_logging() set_seed(42) # Select the classes based on the descriptor type. # DNN uses RDKit features, so we set the descriptor type to RDKit and select configuration, dataset, # and model classes according to it. descriptor_type = \"RDKit\" config_class = configure_selector(descriptor_type) dataset_class = dataset_selector(descriptor_type) model_class = model_selector(descriptor_type) # Specify the configuration of the experiment. # Notice that although we directly edit the config object here, a more appropriate way of doing this is # passing arguments through the shell or json scripts when we are running the experiments through the terminal. config = config_class(descriptor_type) config.model_name = \"DNN\" config.feature_type = \"rdkit\" config.data_folder = \"../data/files/\" config.dataset_name = \"bbbp\" config.result_folder = \"../output-demo/\" config.uncertainty_method = \"none\" # here \"none\" refers to \"Deterministic\" config.retrain_model = True # We only train the model for a few epochs for the demo. config.n_epochs = 50 # activate training timer config.time_training = True # Post initialization of the arguments. config.__post_init__() # Load dataset metadata, validate the arguments, and log the configuration. _ = config.get_meta().validate().log() The configuration details are printed out in your terminal by calling config.log() . Similar to configuration, we automatically infer the dataset and collate function classes according to the descriptor type we set above. Then, we initialize the training, validation, and test datasets. # Load and process the training, validation and test datasets dataset_class, collator_class = dataset_selector(descriptor_type) training_dataset = dataset_class().prepare(config=config, partition=\"train\") valid_dataset = dataset_class().prepare(config=config, partition=\"valid\") test_dataset = dataset_class().prepare(config=config, partition=\"test\") Afterward, we can initialize the trainer and model with our configuration. model_selector automatically detects the model type according to the descriptor. In this case, DNN is the selected model. Then, the trainer initializes the model with arguments defined in the configuration. # Inintialized the trainer with the configuration and datasets trainer = Trainer( config=config, model_class=model_selector(descriptor_type), training_dataset=training_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset, collate_fn=collator_class(config), ).initialize(config=config) Once the trainer is initialized, we can call trainer.run() to do the training. # Run the training, validation and test process. # The model checkpoint and predicted results will be automatically saved in the specified output folder. trainer.run() Temperature Scaling -- training Training the DNN model with Temperature Scaling is basically identical to training with the Deterministic method. The only difference is that we need to define the uncertainty_method in config as \"TemperatureScaling\" instead of \"none\" . wandb.init(mode=\"disabled\",) # Change some configuration items. config.uncertainty_method = \"TemperatureScaling\" config.retrain_model = False config.n_ts_epochs = 10 # number of epochs for training the temperature scaling layer. config.__post_init__() _ = config.validate().log() # Re-inintialized the trainer with the updated configuration. # The datasets are not changed. trainer = Trainer( config=config, model_class=model_selector(descriptor_type), training_dataset=training_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset, collate_fn=collator_class(config), ).initialize(config=config) # Run the training, validation and test process. # The trainer will load the model checkpoint from the Deterministic run and # continue training the temperature scaling layer. # Notice that not all UQ methods support continued training. For example, BBP requires training from scratch. trainer.run() Evaluation Here, we provide a simplified version of metric calculation. Please check <project root>/assist/result_get_metrics.py for the full function. import os.path as osp import pandas as pd from muben.utils.metrics import classification_metrics from muben.utils.io import load_results # Define the path to the predicted results. \"det\" stands for \"Deterministic\"; \"ts\" stands for \"Temperature Scaling\". det_result = osp.join( config.result_folder, config.dataset_name, f\"{config.model_name}-{config.feature_type}\", \"none\", f\"seed-{config.seed}\", \"preds\", \"0.pt\" ) ts_result = osp.join( config.result_folder, config.dataset_name, f\"{config.model_name}-{config.feature_type}\", \"TemperatureScaling\", f\"seed-{config.seed}\", \"preds\", \"0.pt\" ) # Load the predicted results. det_preds, _, lbs, masks = load_results([det_result]) ts_preds, _, _, _ = load_results([ts_result]) # Calculate the metrics. det_metrics = classification_metrics(det_preds, lbs, masks) ts_metrics = classification_metrics(ts_preds, lbs, masks) det_metrics = {k: v['macro-avg'] for k, v in det_metrics.items()} ts_metrics = {k: v['macro-avg'] for k, v in ts_metrics.items()} # Present the results in a dataframe. det_metrics_df = pd.DataFrame({\"Deterministic\": det_metrics, \"TemperatureScaling\": ts_metrics}) print(det_metrics_df.T) The result will be presented as a table the columns being metrics and rows being the UQ method.","title":"Using MUBen Package"},{"location":"train.python/#using-muben-package","text":"In this demonstration, we'll guide you through foundational training and testing of MUBen using the BBBP dataset as a minimal example. We've chosen the DNN as our backbone model because it is both efficient and offers satisfactory performance. For UQ, we'll evaluate both the Deterministic method (referred to as \"none\" within MUBen) and Temperature Scaling. While the procedures for other backbone models, UQ methods, or datasets are largely similar, you can explore specific variations by referring to API documentation. Info For a practical example of our setup, refer to the demo Jupyter Notebook provided on GitHub.","title":"Using muben Package"},{"location":"train.python/#importing-packages","text":"The first step is to import all the necessary packages from the MUBen source code that defines the datasets, backbone models, UQ methods, and trainers. import logging import wandb from transformers import set_seed from muben.utils.selectors import configure_selector, dataset_selector, model_selector from muben.train import Trainer from muben.utils.io import set_logging # initialize logger logger = logging.getLogger(__name__)","title":"Importing packages"},{"location":"train.python/#deterministic-method-training","text":"We first train the DNN model Deterministically. That is, we do not apply any UQ method to the model. Instead, we directly use its post-output-activation probabilities as its estimated reliability to its prediction. Here we pass necessary hyper-parameters to the configuration to control the training process. # Set up the logging format and random seed. # We do not use wandb for this demo, so we set its mode to \"disabled\". set_logging() set_seed(42) # Select the classes based on the descriptor type. # DNN uses RDKit features, so we set the descriptor type to RDKit and select configuration, dataset, # and model classes according to it. descriptor_type = \"RDKit\" config_class = configure_selector(descriptor_type) dataset_class = dataset_selector(descriptor_type) model_class = model_selector(descriptor_type) # Specify the configuration of the experiment. # Notice that although we directly edit the config object here, a more appropriate way of doing this is # passing arguments through the shell or json scripts when we are running the experiments through the terminal. config = config_class(descriptor_type) config.model_name = \"DNN\" config.feature_type = \"rdkit\" config.data_folder = \"../data/files/\" config.dataset_name = \"bbbp\" config.result_folder = \"../output-demo/\" config.uncertainty_method = \"none\" # here \"none\" refers to \"Deterministic\" config.retrain_model = True # We only train the model for a few epochs for the demo. config.n_epochs = 50 # activate training timer config.time_training = True # Post initialization of the arguments. config.__post_init__() # Load dataset metadata, validate the arguments, and log the configuration. _ = config.get_meta().validate().log() The configuration details are printed out in your terminal by calling config.log() . Similar to configuration, we automatically infer the dataset and collate function classes according to the descriptor type we set above. Then, we initialize the training, validation, and test datasets. # Load and process the training, validation and test datasets dataset_class, collator_class = dataset_selector(descriptor_type) training_dataset = dataset_class().prepare(config=config, partition=\"train\") valid_dataset = dataset_class().prepare(config=config, partition=\"valid\") test_dataset = dataset_class().prepare(config=config, partition=\"test\") Afterward, we can initialize the trainer and model with our configuration. model_selector automatically detects the model type according to the descriptor. In this case, DNN is the selected model. Then, the trainer initializes the model with arguments defined in the configuration. # Inintialized the trainer with the configuration and datasets trainer = Trainer( config=config, model_class=model_selector(descriptor_type), training_dataset=training_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset, collate_fn=collator_class(config), ).initialize(config=config) Once the trainer is initialized, we can call trainer.run() to do the training. # Run the training, validation and test process. # The model checkpoint and predicted results will be automatically saved in the specified output folder. trainer.run()","title":"Deterministic method -- training"},{"location":"train.python/#temperature-scaling-training","text":"Training the DNN model with Temperature Scaling is basically identical to training with the Deterministic method. The only difference is that we need to define the uncertainty_method in config as \"TemperatureScaling\" instead of \"none\" . wandb.init(mode=\"disabled\",) # Change some configuration items. config.uncertainty_method = \"TemperatureScaling\" config.retrain_model = False config.n_ts_epochs = 10 # number of epochs for training the temperature scaling layer. config.__post_init__() _ = config.validate().log() # Re-inintialized the trainer with the updated configuration. # The datasets are not changed. trainer = Trainer( config=config, model_class=model_selector(descriptor_type), training_dataset=training_dataset, valid_dataset=valid_dataset, test_dataset=test_dataset, collate_fn=collator_class(config), ).initialize(config=config) # Run the training, validation and test process. # The trainer will load the model checkpoint from the Deterministic run and # continue training the temperature scaling layer. # Notice that not all UQ methods support continued training. For example, BBP requires training from scratch. trainer.run()","title":"Temperature Scaling -- training"},{"location":"train.python/#evaluation","text":"Here, we provide a simplified version of metric calculation. Please check <project root>/assist/result_get_metrics.py for the full function. import os.path as osp import pandas as pd from muben.utils.metrics import classification_metrics from muben.utils.io import load_results # Define the path to the predicted results. \"det\" stands for \"Deterministic\"; \"ts\" stands for \"Temperature Scaling\". det_result = osp.join( config.result_folder, config.dataset_name, f\"{config.model_name}-{config.feature_type}\", \"none\", f\"seed-{config.seed}\", \"preds\", \"0.pt\" ) ts_result = osp.join( config.result_folder, config.dataset_name, f\"{config.model_name}-{config.feature_type}\", \"TemperatureScaling\", f\"seed-{config.seed}\", \"preds\", \"0.pt\" ) # Load the predicted results. det_preds, _, lbs, masks = load_results([det_result]) ts_preds, _, _, _ = load_results([ts_result]) # Calculate the metrics. det_metrics = classification_metrics(det_preds, lbs, masks) ts_metrics = classification_metrics(ts_preds, lbs, masks) det_metrics = {k: v['macro-avg'] for k, v in det_metrics.items()} ts_metrics = {k: v['macro-avg'] for k, v in ts_metrics.items()} # Present the results in a dataframe. det_metrics_df = pd.DataFrame({\"Deterministic\": det_metrics, \"TemperatureScaling\": ts_metrics}) print(det_metrics_df.T) The result will be presented as a table the columns being metrics and rows being the UQ method.","title":"Evaluation"}]}